<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Centiman: Elastic, High Performance Optimistic Concurrency Control by Watermarking</title>
    <url>/2022/05/15/Centiman-Elastic-High-Performance-Optimistic-Concurrency-Control-by-Watermarking/</url>
    <content><![CDATA[<p>ACID over KVS</p>
<p>OCC</p>
<p>Validation is sharded and proceeds in parallel</p>
<p><img src="/2022/05/15/Centiman-Elastic-High-Performance-Optimistic-Concurrency-Control-by-Watermarking/centiman.png" alt="Architecture"></p>
<span id="more"></span>

<p>Put(key, value, timestamp)</p>
<ul>
<li>Ignored when timestamp is smaller than current</li>
</ul>
<p>Get(key) -&gt; (value, version)</p>
<p>Read -&gt; Validation -&gt; Write</p>
<ul>
<li>Validation for each transaction happens at one or more validators and is carried out in timestamp order.</li>
<li>Buffer previous WriteSets, used for later ReadSet check.</li>
<li>The storage rejects all writes to a record r by transaction i if a version j &gt; i is already installed for r.</li>
</ul>
<p>Spurious aborts</p>
<ul>
<li>Txn make validations on A and B. A commit while B abort, it will pollute A’s WriteSet and cause spurious aborts.</li>
</ul>
<p>Validation with watermarks</p>
<ul>
<li>Watermarks are metadata that propagate through the system information about the timestamp of the latest completed transaction.</li>
<li>If record r has watermark w at time t, then at time t all transactions with timestamp i ≤ w have either already installed their writes on r or will never make any writes to r.</li>
</ul>
<p>Validation for Read-Only transactions</p>
<ul>
<li>For a timestamp i, we say that a datastore is at snapshot i if no version of any record with a timestamp j ≤ i will ever be installed in the future, and no version of any record with a timestamp k &gt; i exists in the datastore.</li>
<li>We say that a transaction reads at snapshot i if all the reads that it performs see the same values and versions as they would in a datastore at snapshot i.</li>
</ul>
<p><img src="/2022/05/15/Centiman-Elastic-High-Performance-Optimistic-Concurrency-Control-by-Watermarking/centiman_proc.png" alt="Algorithm"></p>
<p>Validator scaling</p>
<ul>
<li>Global Master informs all processors to send validation requests based both on the old and the new partitioning.</li>
<li>At a suitable point, the global master decides to switch to the new partitioning synchronically.</li>
</ul>
<p>Implementation</p>
<ul>
<li>Slide time window, validation before the current window will abort.</li>
<li>Gossip protocol.</li>
<li>To compute a watermark for a read, each processor uses the minimum of its own local watermark and the cached watermarks of other processors</li>
<li>Each processor node maintains a write-ahead log to enable a redo of writes to the datastore.</li>
</ul>
<h3 id="一个事务的完整生命周期"><a href="#一个事务的完整生命周期" class="headerlink" title="一个事务的完整生命周期"></a>一个事务的完整生命周期</h3><p>读取阶段</p>
<ul>
<li>处理结点维护一个本地的已应用事务提交时间戳（watermark，此时间戳之前的数据更新已写入kv存储）及其它节点已应用事务提交时间戳的缓存（缓存定期异步更新）</li>
<li>每次读操作读取最新版本的kv，处理结点会计算最新的watermark时间（取全局最小），将key、version、watermark记入读集；写入操作需将kv缓存到处理结点的事务私有内存空间并将key记入写集</li>
</ul>
<p>验证阶段</p>
<ul>
<li>只读和读写事务都需要走验证流程（优化：处理结点若发现待验证事务的所有读时间戳都小于事务第一次读时的watermark，则直接向客户端返回提交）</li>
<li>处理结点给待验证事务赋值一个全局单调递增的提交时间戳</li>
<li>将执行阶段记录的读集、写集按照key的某种分片规则分别发送到对应的验证结点，同时将事务私有内存中的数据异步写日志</li>
<li>每个验证节点维护一个滑动时间窗口，小于滑动时间窗口到来的验证请求则直接返回验证失败；落在滑动窗口内的验证请求按照事务提交时间戳顺序进行处理并持续推进滑动窗口</li>
<li>采用BOCC算法进行验证，对于事务在某个分片验证节点读集中的每个key，在验证结点缓存的事务写集中查找所有在读key时间戳和待验证事务提交时间戳之间提交的事务并验证读key是否与已提交事务的写集冲突 （优化：如果读key时间戳小于记录的watermark时间戳，则冲突检查区间可以缩小为在watermark时间戳和待验证事务提交时间戳之间）</li>
<li>若冲突，则中止事务；否则，将待提交事务的写集缓存在验证节点用于后续新事务的验证并提交事务</li>
<li>如果所有相关验证结点都同意提交事务，则发起验证的处理结点写提交日志并通知客户端，转入写入阶段；否则直接通知客户端事务已中止（可能存在有些验证结点认为应该提交，有些验证结点认为应该终止的状态，虽然事务整体是终止状态，但部分验证结点会存在冲突误判，论文中也是依赖watermark机制尽量减少误判）</li>
</ul>
<p>写入阶段</p>
<ul>
<li>处理结点将事务本地内存中的更新内容写入kv存储（写入过程不要求保证原子性，允许其它事务读到部分写入的新值；通过kv存储的MVCC机制保证提交时间戳靠后的事务写入的数据不会被提交时间戳靠前的事务写入的数据覆盖）</li>
<li>待全部写入成功后，更新本地watermark并异步记录事务已完成日志</li>
</ul>
]]></content>
      <tags>
        <tag>OCC</tag>
      </tags>
  </entry>
  <entry>
    <title>FoundationDB: A Distributed Unbundled Transactional Key Value Store</title>
    <url>/2022/06/09/FoundationDB-A-Distributed-Unbundled-Transactional-Key-Value-Store/</url>
    <content><![CDATA[<p>FoundationDB 和传统的 key value store 相比，一方面在存储层实现的是强一致 ACID，另一方面通过可扩展的方式支持更多数据模型，并发控制采用 OCC 同时不支持超过 5s 的长事务。</p>
<span id="more"></span>

<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="/2022/06/09/FoundationDB-A-Distributed-Unbundled-Transactional-Key-Value-Store/arch.png" alt="架构"></p>
<p>FoundationDB 架构的核心是<strong>松耦合</strong>，整体可以分为 Control Plane 和 Data Plane 两个模块。</p>
<ul>
<li>Control Plane 负责系统的管理和监控，使用 Active Disk Paxos 保证高可用性，并选举出单个的 Cluster Controller，controller 会创建另外几个单实例进程：Data Distributor，Rate Keeper，Sequencer<ul>
<li>Sequencer 负责给事务分发 read version 和 commit version</li>
<li>Data Distributor 负责监控 Storage Server 集群状态以及负载均衡</li>
<li>Rate Keeper 负责流控，避免系统 overload</li>
</ul>
</li>
<li>Data Plane 负责用户和系统数据的存储，其中 Transaction System 负责处理写请求，Storage System 负责处理读请求，不同系统之间完全解耦，同时可以各自独立扩展<ul>
<li>TS 层负责事务处理，由 Sequencer 创建 Proxy &#x2F; Resolver，整个 TS 层是无状态的，便于发生 failure 时，快速整体重启</li>
<li>LS 层负责 WAL 的存储，按照 key range 做分片存储，且每个分片有多个副本</li>
<li>SS 层负责实际数据的存储，和 LS 的分片对应，每个分片有自己的 WAL 日志，底层目前使用的是 SQLite，后续会考虑Rocksdb</li>
</ul>
</li>
</ul>
<h2 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a>事务处理</h2><p>FoundationDB 利用 OCC + MVCC 的策略来实现串行化事务。</p>
<ul>
<li>读请求<br>client 连接 Proxy，获取读时间戳，Proxy 向 Sequencer 获取 read version 并返回 client，client 利用 read version 从 storage server 直接读取目标版本数据，在本地进行物化并缓存</li>
<li>写请求<br>事务提交时带着 read set + write set 发给 Proxy，Proxy 首先向 Sequencer 获取 commit version，然后发送给 Resolver做冲突检测（Resovler 也是根据 key range 分片启动多个实例，这样可以并发做冲突检测）</li>
</ul>
<p>FDB 实现的是可串行化事务，commit version 的顺序就是事务提交顺序，因此可以认为事务需要在 commit 点瞬时完成，冲突检测就是判断在 (read version, commit version) 之间，是否并发事务写入了冲突的数据。其中 Resolver 的冲突检测算法如下图所示：</p>
<p><img src="/2022/06/09/FoundationDB-A-Distributed-Unbundled-Transactional-Key-Value-Store/conflict_detect.png" alt="冲突检测算法"></p>
<p>为了提高冲突检测效率，Resolver 使用 skiplist 维护数据的 LastCommit 信息，即修改的 key range -&gt; commit version 的映射，记录 key range 最近一次的 commit version，便于找到对某个 key&#x2F;key-range 最近一次 commit version 是否在当前事务的 (read version, commit version)之间，不冲突即用当前事务的 commit version 更新 LastCommit。</p>
<p>这里有一个问题，由于是多个 Resovler 并发检测冲突，可能一些 Resolver 局部认为是无冲突的，因此更新了自己维护的LastCommit 结构，导致后续不应该失败的事务发生冲突(false-positive）。FDB认为这不是大问题，首先它面向多租户应用，冲突较少，一般事务都会落入一个 Resovler。此外即使失败后重试，新的事务的 read version 增长后，超过这个伪提交事务的 commit version 即可。</p>
<p>除了 read-write 事务，还有 read-only 事务，只获取 read version 从 SS 读取数据，然后 client 直接提交就可以，等同于在 read version 瞬时完成，不需要检测冲突。 此外在 read-write 事务中还允许进行 snapshot read，这种 read 不放入 read set 中，不做冲突检测。</p>
<p>所有 Resovler 返回成功时，Proxy 认为事务可以提交，向 LogServer 发送 WAL 进行多副本同步复制，日志落盘后 Proxy 认为事务提交成功，返回给 client。同时 Storage Server 异步的从 LS 获取 log entry 并 apply，即使log entry 还没有落盘也会 apply，FDB 通过采用这种激进的物化策略来保证 data 和 log 之间的低延迟。</p>
<p>可串行化的并发控制使得 log entry 之间形成了严格的顺序，大大简化了 log 管理的逻辑，可以用 version 来表示 LSN，针对每个 key，它所对应的实际是一个有序的 log entry 队列，依次 apply 就可以物化成最新版本。</p>
<p><img src="/2022/06/09/FoundationDB-A-Distributed-Unbundled-Transactional-Key-Value-Store/logsync.png" alt="Proxy 写 log 流程"></p>
<p>Proxy 本地有缓存一份 key range -&gt; SS 的映射关系，这样就可以知道要写入哪些 SS 和对应的 LS。例如上图中，LS1 + LS4 是要写入的 LS，由于是3副本，需要再额外写一个 LS，其余的 LS 也要发送，但只传递 Log Header，其中包含的最主要信息是当前的 LSN 和 Proxy 上的 KCV，即本 Proxy 已知的最大已提交事务，LS 收到后会更新自己本地的 KCV，这个 KCV 在 recovery 时会使用。</p>
<p>LS 上的 WAL -&gt; SS 和 apply redo 并不在 commit 流程中，是异步持续完成，因此可以说 FDB 也遵循了 ‘log is data’ 的思想。这种方式 client 做 read 一般可以读到目标 version 的数据，如果不行就等待或者向其他副本请求，都不行的话，可以超时后重试。<br>由于是异步 apply，可以做 batching，将一批更新缓存在 SS 上，批量刷盘提高 IO 效率。但这里也有个问题，由于 LS 中在内存中（未提交）的 entry 也可能被apply，因此 SS 是有脏数据的，在 recovery 时要 rollback。</p>
<h2 id="数据可靠性"><a href="#数据可靠性" class="headerlink" title="数据可靠性"></a>数据可靠性</h2><p>FDB 由于 redo log apply 是在后台持续进行的，因此本质上它将 redo apply 从 recovery 中解耦出来，等于持续在 checkpointing，在 recovery 期间不需要做 redo apply，只是确认当前的 log 序列需要恢复到哪个位置即可，后续基于 log -&gt; data 的过程仍然是异步，以此保证了 recovery 的速度。</p>
<p><img src="/2022/06/09/FoundationDB-A-Distributed-Unbundled-Transactional-Key-Value-Store/recovery.png" alt="FDB Recovery"></p>
<p>发现 failure 后，旧的 Sequencer 退出，新 Sequencer 启动，并从 Coordinator 获取老的 TS 的配置信息，包括旧的 LS 的位置等，同时给 Coordinator 加个全局锁，避免并发 recovery，然后关闭老的 LS，禁止接收新的 log 写入，开始恢复，恢复完成后启动 TS 接收用户请求。</p>
<p>Proxy 和 Resolver 都是 stateless 的，直接重启即可，只有 LogServer 有 log 信息。由于在日常提交写日志时，Proxy 会把本地记录的 KCV 广播给所有 LS，LS 中就记录了自己见过的最大的 KCV。选取所有 LS 中 KCV 的最大值，在这个值之前的事务，其日志已经完全复制并落盘，且已告知 Proxy，可以作为上一个 epoch 的终点，称为 PEV（previous epoch’s end version）。</p>
<p>同时每个 LogServer 都记录了本地已持久化的 version (DV)，选取所有 DV 中的最小值，作为 Recovery Version(RV)，在 [PEV, RV] 之间的日志，已持久化且不在内存中，但不确定是否已提交（因为 Proxy 没有该信息，可能崩溃的那个没持久化），因此这部分需要进行恢复，而大于 RV 的 log entry，肯定没有多副本都持久化，因此不可能提交，这部分要undo。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><ol>
<li>Transaction batching<br>在 Proxy 上为了减少与 Sequencer&#x2F;LS 的交互成本，可以把不冲突的并发事务合并，获取同一个 commit version，并一起下发到 LogServer，相当于 group commit。<br>这个策略是可以自适应的，在系统负载不大时，为了减少延迟，可以减小 batch 大小，当系统重负载时，为了保证吞吐则可以加大 batch。</li>
<li>Atomic operations<br>对于一些只写不读的操作，其相互之间可以不做冲突检测，直接获取提交时间戳就可以，这对于某些 counter 类型的操作会提高效率，因为避免了从 storage 的一次读，也避免了 resolve confilct。</li>
</ol>
]]></content>
      <tags>
        <tag>OCC</tag>
        <tag>FoundationDB</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title>FoundationDB Record Layer: A Multi-Tenant Structured Datastore</title>
    <url>/2022/06/13/FoundationDB-Record-Layer-A-Multi-Tenant-Structured-Datastore/</url>
    <content><![CDATA[<p>FoundationDB Record Layer 是建立在 FoundationDB 之上的类关系模型的结构化数据层，支持多租户，以 library 方式提供给应用，目前没有实现 SQL。</p>
<span id="more"></span>

<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="/2022/06/13/FoundationDB-Record-Layer-A-Multi-Tenant-Structured-Datastore/arch.png" alt="Record Layer 架构"></p>
<p>FoundationDB Record Layer 的租户粒度是 logic database，也叫 record store，其实就是一段逻辑上连续（前缀一样）的 key-value。</p>
<p>如上图所示，FoundationDB Record Layer 的整体架构：</p>
<ul>
<li>应用程序（Application）通过 library 的方式使用 FoundationDB Record Layer。</li>
<li>一个 record store 包含 record、indexes 和 metadata，它们都被编码成一段连续（前缀一样）的 key-value，存储在 FoundationDB。</li>
<li>MetaData Store 主要存储的是 schema 的定义，可以保存到 FoundationDB 或者其他存储。大部分情况下，这些数据都会被 cache 在 client。</li>
</ul>
<p><img src="/2022/06/13/FoundationDB-Record-Layer-A-Multi-Tenant-Structured-Datastore/cloudkit.png" alt="CloudKit 使用 FoundationDB Record Layer"></p>
<p>苹果公司内部的 CloudKit 框架使用 FoundationDB Record Layer 管理数据：一个用户（User）的一个应用（Application）的数据被组织成一个 record store（租户）。所以，CloudKit 使用 FoundationDB Record Layer 维护的租户数量为：用户数 * 应用数，数量上大概在数十亿级别。</p>
<h2 id="类关系模型"><a href="#类关系模型" class="headerlink" title="类关系模型"></a>类关系模型</h2><p>FoundationDB Record Layer 通过 Protocol Buffer message 来定义 schema，同时支持多种内置的索引类型。为了适应各种业务需求，FoundationDB Record Layer 在设计上提供了一定的扩展性，应用可以通过类似插件的方式实现自己的索引类型。</p>
<p>在 FoundationDB Record Layer 里，“索引（index）”是一个更宽泛的概念。我们一般提到数据库索引，在 FoundationDB Record Layer 这里被成为 VALUE indexes。</p>
<p>为了实现各种类型的“索引”，FoundationDB Record Layer 引入了两个概念：</p>
<ul>
<li>key expression<br>key expression 就是一个根据 record 生成 index-key 的生成器</li>
<li>index maintanance<br>index maintanance 是用来当 record 发生变化时维护对应的索引</li>
</ul>
<p>这两者类似一个拦截器，拦截每一个 record 的变化信息，生成相应的 key-value。只要经过 key expression 和 index maintanance 生成的 key-value，在 FoundationDB Record Layer 里都被称为“索引”。</p>
]]></content>
      <tags>
        <tag>OCC</tag>
        <tag>FoundationDB</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang HTTP transport</title>
    <url>/2022/05/12/Golang-HTTP-transport/</url>
    <content><![CDATA[<p>使用golang net&#x2F;http库发送http请求，最后都是调用 transport的 RoundTrip方法</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> RoundTripper <span class="keyword">interface</span> &#123;</span><br><span class="line">    RoundTrip(*Request) (*Response, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p><code>RoundTrip executes a single HTTP transaction, returning the Response for the request req.</code> (RoundTrip 代表一个http事务，给一个请求返回一个响应)<br>说白了，就是你给它一个request,它给你一个response</p>
<p>下面我们来看一下他的实现，对应源文件<code>net/http/transport.go</code>，我感觉这里是http package里面的精髓所在，go里面一个struct就跟一个类一样，transport这个类长这样的</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Transport <span class="keyword">struct</span> &#123;</span><br><span class="line">    idleMu     sync.Mutex</span><br><span class="line">    wantIdle   <span class="type">bool</span> <span class="comment">// user has requested to close all idle conns</span></span><br><span class="line">    idleConn   <span class="keyword">map</span>[connectMethodKey][]*persistConn</span><br><span class="line">    idleConnCh <span class="keyword">map</span>[connectMethodKey]<span class="keyword">chan</span> *persistConn</span><br><span class="line"></span><br><span class="line">    reqMu       sync.Mutex</span><br><span class="line">    reqCanceler <span class="keyword">map</span>[*Request]<span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line">    altMu    sync.RWMutex</span><br><span class="line">    altProto <span class="keyword">map</span>[<span class="type">string</span>]RoundTripper <span class="comment">// nil or map of URI scheme =&gt; RoundTripper</span></span><br><span class="line">    <span class="comment">//Dial获取一个tcp 连接，也就是net.Conn结构，你就记住可以往里面写request</span></span><br><span class="line">    <span class="comment">//然后从里面搞到response就行了</span></span><br><span class="line">    Dial <span class="function"><span class="keyword">func</span><span class="params">(network, addr <span class="type">string</span>)</span></span> (net.Conn, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>篇幅所限， https和代理相关的我就忽略了， 两个 <code>map</code> 为 <code>idleConn</code>、<code>idleConnCh</code>，<code>idleConn</code> 是保存从 connectMethodKey （代表着不同的协议 不同的host，也就是不同的请求）到 persistConn 的映射， <code>idleConnCh</code> 用来在并发http请求的时候在多个 goroutine 里面相互发送持久连接，也就是说， 这些持久连接是可以重复利用的， 你的http请求用某个<code>persistConn</code>用完了，通过这个<code>channel</code>发送给其他http请求使用这个<code>persistConn</code>，然后我们找到<code>transport</code>的<code>RoundTrip</code>方法</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Transport)</span></span> RoundTrip(req *Request) (resp *Response, err <span class="type">error</span>) &#123;</span><br><span class="line">    ...</span><br><span class="line">    pconn, err := t.getConn(req, cm)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        t.setReqCanceler(req, <span class="literal">nil</span>)</span><br><span class="line">        req.closeBody()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pconn.roundTrip(treq)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>前面对输入的错误处理部分我们忽略， 其实就2步，先获取一个TCP长连接，所谓TCP长连接就是三次握手建立连接后不<code>close</code>而是一直保持重复使用（节约环保） 然后调用这个持久连接persistConn 这个struct的roundTrip方法</p>
<p>我们跟踪第一步</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Transport)</span></span> getConn(req *Request, cm connectMethod) (*persistConn, <span class="type">error</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> pc := t.getIdleConn(cm); pc != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="comment">// set request canceler to some non-nil function so we</span></span><br><span class="line">        <span class="comment">// can detect whether it was cleared between now and when</span></span><br><span class="line">        <span class="comment">// we enter roundTrip</span></span><br><span class="line">        t.setReqCanceler(req, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;&#125;)</span><br><span class="line">        <span class="keyword">return</span> pc, <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">type</span> dialRes <span class="keyword">struct</span> &#123;</span><br><span class="line">        pc  *persistConn</span><br><span class="line">        err <span class="type">error</span></span><br><span class="line">    &#125;</span><br><span class="line">    dialc := <span class="built_in">make</span>(<span class="keyword">chan</span> dialRes)</span><br><span class="line">    <span class="comment">//定义了一个发送 persistConn的channel</span></span><br><span class="line"></span><br><span class="line">    prePendingDial := prePendingDial</span><br><span class="line">    postPendingDial := postPendingDial</span><br><span class="line"></span><br><span class="line">    handlePendingDial := <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> prePendingDial != <span class="literal">nil</span> &#123;</span><br><span class="line">            prePendingDial()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            <span class="keyword">if</span> v := &lt;-dialc; v.err == <span class="literal">nil</span> &#123;</span><br><span class="line">                t.putIdleConn(v.pc)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> postPendingDial != <span class="literal">nil</span> &#123;</span><br><span class="line">                postPendingDial()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cancelc := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">    t.setReqCanceler(req, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; <span class="built_in">close</span>(cancelc) &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启动了一个goroutine, 这个goroutine 获取里面调用dialConn搞到</span></span><br><span class="line">    <span class="comment">// persistConn, 然后发送到上面建立的channel  dialc里面，</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        pc, err := t.dialConn(cm)</span><br><span class="line">        dialc &lt;- dialRes&#123;pc, err&#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    idleConnCh := t.getIdleConnCh(cm)</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> v := &lt;-dialc:</span><br><span class="line">        <span class="comment">// dialc 我们的 dial 方法先搞到通过 dialc通道发过来了</span></span><br><span class="line">        <span class="keyword">return</span> v.pc, v.err</span><br><span class="line">    <span class="keyword">case</span> pc := &lt;-idleConnCh:</span><br><span class="line">        <span class="comment">// 这里代表其他的http请求用完了归还的persistConn通过idleConnCh这个</span></span><br><span class="line">        <span class="comment">// channel发送来的</span></span><br><span class="line">        handlePendingDial()</span><br><span class="line">        <span class="keyword">return</span> pc, <span class="literal">nil</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-req.Cancel:</span><br><span class="line">        handlePendingDial()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;net/http: request canceled while waiting for connection&quot;</span>)</span><br><span class="line">    <span class="keyword">case</span> &lt;-cancelc:</span><br><span class="line">        handlePendingDial()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">&quot;net/http: request canceled while waiting for connection&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里面的代码写的很有讲究 , 上面代码里面我也注释了， 定义了一个发送 <code>persistConn</code>的channel<code> dialc</code>， 启动了一个<code>goroutine</code>, 这个<code>goroutine</code> 获取里面调用<code>dialConn</code>搞到<code>persistConn</code>, 然后发送到<code>dialc</code>里面，主协程<code>goroutine</code>在 <code>select</code>里面监听多个<code>channel</code>,看看哪个通道里面先发过来 <code>persistConn</code>，就用哪个，然后<code>return</code>。</p>
<p>这里要注意的是 <code>idleConnCh</code> 这个通道里面发送来的是其他的http请求用完了归还的<code>persistConn</code>， 如果从这个通道里面搞到了，<code>dialc</code>这个通道也等着发呢，不能浪费，就通过<code>handlePendingDial</code>这个方法把<code>dialc</code>通道里面的<code>persistConn</code>也发到<code>idleConnCh</code>，等待后续给其他http请求使用。</p>
<p>还有就是，读者可以翻一下代码，每个新建的persistConn的时候都把tcp连接里地输入流，和输出流用br（<code>br *bufio.Reader</code>）,和bw(<code>bw *bufio.Writer</code>)包装了一下，往bw写就写到tcp输入流里面了，读输出流也是通过br读，并启动了读循环和写循环</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pconn.br = bufio.NewReader(noteEOFReader&#123;pconn.conn, &amp;pconn.sawEOF&#125;)</span><br><span class="line">pconn.bw = bufio.NewWriter(pconn.conn)</span><br><span class="line">go pconn.readLoop()</span><br><span class="line">go pconn.writeLoop()</span><br></pre></td></tr></table></figure>

<p>我们跟踪第二步<code>pconn.roundTrip</code> 调用这个持久连接persistConn 这个struct的<code>roundTrip</code>方法。<br>先瞄一下 <code>persistConn</code> 这个struct</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> persistConn <span class="keyword">struct</span> &#123;</span><br><span class="line">    t        *Transport</span><br><span class="line">    cacheKey connectMethodKey</span><br><span class="line">    conn     net.Conn</span><br><span class="line">    tlsState *tls.ConnectionState</span><br><span class="line">    br       *bufio.Reader       <span class="comment">// 从tcp输出流里面读</span></span><br><span class="line">    sawEOF   <span class="type">bool</span>                <span class="comment">// whether we&#x27;ve seen EOF from conn; owned by readLoop</span></span><br><span class="line">    bw       *bufio.Writer       <span class="comment">// 写到tcp输入流</span></span><br><span class="line">     reqch    <span class="keyword">chan</span> requestAndChan <span class="comment">// 主goroutine 往channnel里面写，读循环从</span></span><br><span class="line">                                 <span class="comment">// channnel里面接受</span></span><br><span class="line">    writech  <span class="keyword">chan</span> writeRequest   <span class="comment">// 主goroutine 往channnel里面写</span></span><br><span class="line">                                 <span class="comment">// 写循环从channel里面接受</span></span><br><span class="line">    closech  <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;       <span class="comment">// 通知关闭tcp连接的channel</span></span><br><span class="line"></span><br><span class="line">    writeErrCh <span class="keyword">chan</span> <span class="type">error</span></span><br><span class="line"></span><br><span class="line">    lk                   sync.Mutex <span class="comment">// guards following fields</span></span><br><span class="line">    numExpectedResponses <span class="type">int</span></span><br><span class="line">    closed               <span class="type">bool</span> <span class="comment">// whether conn has been closed</span></span><br><span class="line">    broken               <span class="type">bool</span> <span class="comment">// an error has happened on this connection; marked broken so it&#x27;s not reused.</span></span><br><span class="line">    canceled             <span class="type">bool</span> <span class="comment">// whether this conn was broken due a CancelRequest</span></span><br><span class="line">    <span class="comment">// mutateHeaderFunc is an optional func to modify extra</span></span><br><span class="line">    <span class="comment">// headers on each outbound request before it&#x27;s written. (the</span></span><br><span class="line">    <span class="comment">// original Request given to RoundTrip is not modified)</span></span><br><span class="line">    mutateHeaderFunc <span class="function"><span class="keyword">func</span><span class="params">(Header)</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>里面是各种channel, 用的是出神入化， 各位要好好理解一下， 我这里画一下</p>
<p>这里有三个goroutine，分别用三个圆圈表示， channel用箭头表示</p>
<p>有两个channel <code>writeRequest</code> 和 <code>requestAndChan</code></p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> writeRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">    req *transportRequest</span><br><span class="line">    ch  <span class="keyword">chan</span>&lt;- <span class="type">error</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主goroutine 往writeRequest里面写，写循环从writeRequest里面接受</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> responseAndError <span class="keyword">struct</span> &#123;</span><br><span class="line">    res *Response</span><br><span class="line">    err <span class="type">error</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> requestAndChan <span class="keyword">struct</span> &#123;</span><br><span class="line">    req *Request</span><br><span class="line">    ch  <span class="keyword">chan</span> responseAndError</span><br><span class="line">    addedGzip <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主goroutine 往requestAndChan里面写，读循环从requestAndChan里面接受。</p>
<p>注意这里的channel都是双向channel，也就是channel 的struct里面有一个chan类型的字段， 比如 <code>reqch chan requestAndChan</code> 这里的 requestAndChan 里面的 <code>ch chan responseAndError</code>。</p>
<p>这个是很牛叉，主 goroutine 通过 reqch 发送requestAndChan 给读循环，然后读循环搞到response后通过 requestAndChan 里面的通道responseAndError把response返给主goroutine，所以我画了一个双向箭头。</p>
<p>我们研究一下代码，我理解下来其实就是三个goroutine通过channel互相协作的过程。</p>
<p>主循环：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pc *persistConn)</span></span> roundTrip(req *transportRequest) (resp *Response, err <span class="type">error</span>) &#123;</span><br><span class="line">    ... 忽略</span><br><span class="line">    <span class="comment">// Write the request concurrently with waiting for a response,</span></span><br><span class="line">    <span class="comment">// in case the server decides to reply before reading our full</span></span><br><span class="line">    <span class="comment">// request body.</span></span><br><span class="line">    writeErrCh := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">error</span>, <span class="number">1</span>)</span><br><span class="line">    pc.writech &lt;- writeRequest&#123;req, writeErrCh&#125;</span><br><span class="line">    <span class="comment">//把request发送给写循环</span></span><br><span class="line">    resc := <span class="built_in">make</span>(<span class="keyword">chan</span> responseAndError, <span class="number">1</span>)</span><br><span class="line">    pc.reqch &lt;- requestAndChan&#123;req.Request, resc, requestedGzip&#125;</span><br><span class="line">    <span class="comment">//发送给读循环</span></span><br><span class="line">    <span class="keyword">var</span> re responseAndError</span><br><span class="line">    <span class="keyword">var</span> respHeaderTimer &lt;-<span class="keyword">chan</span> time.Time</span><br><span class="line">    cancelChan := req.Request.Cancel</span><br><span class="line">WaitResponse:</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> err := &lt;-writeErrCh:</span><br><span class="line">            <span class="keyword">if</span> isNetWriteError(err) &#123;</span><br><span class="line">                <span class="comment">//写循环通过这个channel报告错误</span></span><br><span class="line">                <span class="keyword">select</span> &#123;</span><br><span class="line">                <span class="keyword">case</span> re = &lt;-resc:</span><br><span class="line">                    pc.<span class="built_in">close</span>()</span><br><span class="line">                    <span class="keyword">break</span> WaitResponse</span><br><span class="line">                <span class="keyword">case</span> &lt;-time.After(<span class="number">50</span> * time.Millisecond):</span><br><span class="line">                    <span class="comment">// Fall through.</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                re = responseAndError&#123;<span class="literal">nil</span>, err&#125;</span><br><span class="line">                pc.<span class="built_in">close</span>()</span><br><span class="line">                <span class="keyword">break</span> WaitResponse</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> d := pc.t.ResponseHeaderTimeout; d &gt; <span class="number">0</span> &#123;</span><br><span class="line">                timer := time.NewTimer(d)</span><br><span class="line">                <span class="keyword">defer</span> timer.Stop() <span class="comment">// prevent leaks</span></span><br><span class="line">                respHeaderTimer = timer.C</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="keyword">case</span> &lt;-pc.closech:</span><br><span class="line">            <span class="comment">// 如果长连接挂了， 这里的channel有数据， 进入这个case, 进行处理</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> re = &lt;-resc:</span><br><span class="line">                <span class="keyword">if</span> fn := testHookPersistConnClosedGotRes; fn != <span class="literal">nil</span> &#123;</span><br><span class="line">                    fn()</span><br><span class="line">                &#125;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                re = responseAndError&#123;err: errClosed&#125;</span><br><span class="line">                <span class="keyword">if</span> pc.isCanceled() &#123;</span><br><span class="line">                    re = responseAndError&#123;err: errRequestCanceled&#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span> WaitResponse</span><br><span class="line">        <span class="keyword">case</span> &lt;-respHeaderTimer:</span><br><span class="line">            pc.<span class="built_in">close</span>()</span><br><span class="line">            re = responseAndError&#123;err: errTimeout&#125;</span><br><span class="line">            <span class="keyword">break</span> WaitResponse</span><br><span class="line">            <span class="comment">// 如果timeout，这里的channel有数据， break掉for循环</span></span><br><span class="line">        <span class="keyword">case</span> re = &lt;-resc:</span><br><span class="line">            <span class="keyword">break</span> WaitResponse</span><br><span class="line">           <span class="comment">// 获取到读循环的response, break掉 for循环</span></span><br><span class="line">        <span class="keyword">case</span> &lt;-cancelChan:</span><br><span class="line">            pc.t.CancelRequest(req.Request)</span><br><span class="line">            cancelChan = <span class="literal">nil</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> re.err != <span class="literal">nil</span> &#123;</span><br><span class="line">        pc.t.setReqCanceler(req.Request, <span class="literal">nil</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> re.res, re.err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码主要就干了三件事</p>
<ul>
<li>主goroutine -&gt;requestAndChan -&gt; 读循环goroutine</li>
<li>主goroutine -&gt;writeRequest-&gt; 写循环goroutine</li>
<li>主goroutine 通过select 监听各个channel上的数据， 比如请求取消， timeout，长连接挂了，写流出错，读流出错， 都是其他goroutine 发送过来的， 跟中断一样，然后相应处理，上面也提到了，有些channel是主goroutine通过channel发送给其他goroutine的struct里面包含的channel, 比如 <code>case err := &lt;-writeErrCh:</code> <code>case re = &lt;-resc:</code></li>
</ul>
<p>读循环代码：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pc *persistConn)</span></span> readLoop() &#123;</span><br><span class="line"></span><br><span class="line">    ... 忽略</span><br><span class="line">    alive := <span class="literal">true</span></span><br><span class="line">    <span class="keyword">for</span> alive &#123;</span><br><span class="line"></span><br><span class="line">        ... 忽略</span><br><span class="line">        rc := &lt;-pc.reqch</span><br><span class="line"></span><br><span class="line">        <span class="keyword">var</span> resp *Response</span><br><span class="line">        <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">            resp, err = ReadResponse(pc.br, rc.req)</span><br><span class="line">            <span class="keyword">if</span> err == <span class="literal">nil</span> &amp;&amp; resp.StatusCode == <span class="number">100</span> &#123;</span><br><span class="line">                <span class="comment">//100  Continue  初始的请求已经接受，客户应当继续发送请求的其</span></span><br><span class="line">                <span class="comment">// 余部分</span></span><br><span class="line">                resp, err = ReadResponse(pc.br, rc.req)</span><br><span class="line">                <span class="comment">// 读pc.br（tcp输出流）中的数据，这里的代码在response里面</span></span><br><span class="line">                <span class="comment">//解析statusCode，头字段， 转成标准的内存中的response 类型</span></span><br><span class="line">                <span class="comment">//  http在tcp数据流里面，head和body以 /r/n/r/n分开， 各个头</span></span><br><span class="line">                <span class="comment">// 字段 以/r/n分开</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> resp != <span class="literal">nil</span> &#123;</span><br><span class="line">            resp.TLS = pc.tlsState</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ...忽略</span><br><span class="line">        <span class="comment">//上面处理一些http协议的一些逻辑行为，</span></span><br><span class="line">        rc.ch &lt;- responseAndError&#123;resp, err&#125; <span class="comment">//把读到的response返回给</span></span><br><span class="line">                                             <span class="comment">//主goroutine</span></span><br><span class="line"></span><br><span class="line">        .. 忽略</span><br><span class="line">        <span class="comment">//忽略部分， 处理cancel req中断， 发送idleConnCh归还pc（持久连接）到持久连接池中（map）</span></span><br><span class="line">    pc.<span class="built_in">close</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>无关代码忽略，这段代码主要干了一件事情</p>
<blockquote>
<p>读循环goroutine 通过channel requestAndChan 接受主goroutine发送的request(<code>rc := &lt;-pc.reqch</code>), 并从tcp输出流中读取response， 然后反序列化到结构体中， 最后通过channel 返给主goroutine (<code>rc.ch &lt;- responseAndError&#123;resp, err&#125; </code>)</p>
</blockquote>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pc *persistConn)</span></span> writeLoop() &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> wr := &lt;-pc.writech:   <span class="comment">//接受主goroutine的 request</span></span><br><span class="line">            <span class="keyword">if</span> pc.isBroken() &#123;</span><br><span class="line">                wr.ch &lt;- errors.New(<span class="string">&quot;http: can&#x27;t write HTTP request on broken connection&quot;</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line">            err := wr.req.Request.write(pc.bw, pc.isProxy, wr.req.extra)   <span class="comment">//写入tcp输入流</span></span><br><span class="line">            <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">                err = pc.bw.Flush()</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                pc.markBroken()</span><br><span class="line">                wr.req.Request.closeBody()</span><br><span class="line">            &#125;</span><br><span class="line">            pc.writeErrCh &lt;- err</span><br><span class="line">            wr.ch &lt;- err         <span class="comment">//  出错的时候返给主goroutineto</span></span><br><span class="line">        <span class="keyword">case</span> &lt;-pc.closech:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>写循环就更简单了，select channel中主gouroutine的request，然后写入tcp输入流，如果出错了，channel 通知调用者。</p>
<p>整体看下来，过程都很简单，但是代码中有很多值得我们学习的地方，比如高并发请求如何复用tcp连接，这里是连接池的做法，如果使用多个 goroutine相互协作完成一个http请求，出现错误的时候如何通知调用者中断错误，代码风格也有很多可以借鉴的地方。</p>
]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>[Google] AlloyDB for PostgreSQL under the hood: Intelligent, database-aware storage</title>
    <url>/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/</url>
    <content><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>在 2022 年 Google I&#x2F;O 上发布了 AlloyDB for PostgreSQL，一个完全托管、兼容 PostgreSQL 的数据库，支持弹性存储和计算、智能缓存和 AI&#x2F;ML 支持的管理。此外，AlloyDB 提供了无与伦比的性价比：在性能测试中，它在事务工作负载上的速度比标准 PostgreSQL 快 4 倍以上，分析查询速度高达 100 倍。</p>
<span id="more"></span>

<h3 id="AlloyDB-架构"><a href="#AlloyDB-架构" class="headerlink" title="AlloyDB 架构"></a>AlloyDB 架构</h3><p>AlloyDB 存储层是一个分布式系统，由三个主要部分组成：</p>
<ul>
<li>一种低延迟的 regional log storage service，用于高速的 WAL 写入</li>
<li>负责处理 WAL 并生成 “Materialized(物化)” 数据库页面的 log processing service (LPS)</li>
<li>负责对数据进行容错、分片的 regional block storage，在区域存储发生故障的情况下也能保证持久性</li>
</ul>
<p><img src="/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/overview.png" alt="Overview of PostgreSQL as integrated with the storage service."></p>
<h4 id="数据流程"><a href="#数据流程" class="headerlink" title="数据流程"></a>数据流程</h4><ul>
<li>Primary Instance 持久化 WAL ，将数据库修改操作（INSERT&#x2F;DELETE&#x2F;UPDATE）传送到 log storage。随后，LPS 不断重放这些 WAL 的修改操作，并将最新的数据库页面物化到 block storage。</li>
<li>为了使 Replica Instances 的本地缓存保持最新，AlloyDB 还将 WAL 记录从 Primary Instance 流式传输到 Replica Instances，以通知它们最新的更改。</li>
</ul>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul>
<li>Full compute&#x2F;storage disaggregation<br>LPS 可以根据工作负载进行横向扩展，并在需要时透明地添加更多计算资源来处理日志以避免热点</li>
<li>Storage-layer replication<br>跨多个区域同步复制所有 Data Block</li>
<li>Efficient IO paths &#x2F; no full-page writes<br>对于更新操作，计算层仅将 WAL 传递给存储层，存储层不断重放 WAL。在这种设计中，数据库层不需要 Checkpoint，也不需要通过将完整的 Data Block发送到存储层来避免 torn pages problem</li>
<li>Low-latency WAL writing</li>
<li>Fast creation of read replica instances</li>
<li>Fast restart recovery</li>
<li>Storage-layer backups</li>
</ul>
<h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><h4 id="写入请求"><a href="#写入请求" class="headerlink" title="写入请求"></a>写入请求</h4><p>由客户端向 Primary Instance 发起，在经过 DB 层解析后，变为一组 WAL 发到存储层。在 WAL 同步写入成功后，事务提交成功返回。之后，LPS 会将日志异步的物化为 Data Block。</p>
<p><img src="/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/write.png" alt="Write Process"></p>
<h4 id="读取请求"><a href="#读取请求" class="headerlink" title="读取请求"></a>读取请求</h4><ul>
<li>由客户端向任何 Instance 发起，在 DB 层解析后，如果命中该 DB 层中的 Buffer Cache，则直接返回；否则去更大的、类似二级缓存的 Ultra-fast Cache 中去找，如命中，则仍可不访问存储层。</li>
<li>如 Ultra-fast Cache 中仍然缺少所需 block，则会带上 block id 和 LSN，向存储层发送 block 读取请求，<strong>这里的 Ultra-fast Cache 会不会是 NVM 之类的存储介质？</strong></li>
<li>LSN 用于等待 LPS apply 进度，以保证一致性视图。</li>
</ul>
<p><img src="/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/read.png" alt="Read Process"></p>
<h3 id="存储层弹性伸缩"><a href="#存储层弹性伸缩" class="headerlink" title="存储层弹性伸缩"></a>存储层弹性伸缩</h3><p>Data Block 按组划分到不同的 Shard 中（如一个 Block 是 8KB，一个 Shard 是 10GB，那么一个 Shard 就包含 1310720 个 Block）。每个 Shard 对应一个 LPS，同时 Shard 和 LPS 的映射关系可以会根据 LPS 的伸缩动态变化。</p>
<p><img src="/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/storage.png" alt="LPS Elasticity"></p>
<h3 id="存储层-Replication-和-Recovery"><a href="#存储层-Replication-和-Recovery" class="headerlink" title="存储层 Replication 和 Recovery"></a>存储层 Replication 和 Recovery</h3><p>AlloyDB 的目标是提供数据持久性和高系统可用性，即使在区域性故障的情况下（例如，在数据中心断电或火灾的情况下）也是如此。为此，每个 AlloyDB 实例的存储层分布在三个 Zone 中。每个 Zone 都有一个完整的数据库状态副本，它通过应用来自 log storage 的 WAL 来不断更新 Data Block。<br><img src="/2022/05/22/Google-AlloyDB-for-PostgreSQL-under-the-hood-Intelligent-database-aware-storage/replication.png" alt="Replication"></p>
]]></content>
      <tags>
        <tag>Cloud Native</tag>
        <tag>Disaggregation</tag>
        <tag>Postgres</tag>
      </tags>
  </entry>
  <entry>
    <title>HotRing: A Hotspot-Aware In-Memory Key-Value Store</title>
    <url>/2022/05/15/HotRing-A-Hotspot-Aware-In-Memory-Key-Value-Store/</url>
    <content><![CDATA[<p>Tair<br>(1) mdb是定位于cache缓存，类似于memcache的一个支持kv 内存缓存框架<br>(2) rdb是 定位于cache缓存，采用了redis的内存存储结构的一个支持kv、list等复杂数据结构的缓存框架<br>(3) ldb是一个定位于高性能存储，并可选择内嵌mdb cache加速，这种情况下cache与持久化存储的数据一致性由tair进行维护,支持kv及分级key存储，数据排序的缓存框架（leveldb）</p>
<span id="more"></span>

<p>通常情况下，一个集群中包含2台configserver及多台dataServer。</p>
<p>两台configserver互为主备并通过维护和dataserver之间的心跳获知集群中存活可用的dataserver，构建数据在集群中的分布信息（对照表）。</p>
<p>dataserver负责数据的存储，并按照configserver的指示完成数据的复制和迁移工作。</p>
<p>client在启动的时候，从configserver获取数据分布信息，根据数据分布信息和相应的dataserver交互完成用户的请求。</p>
<p>invalidserver主要负责对等集群的删除和隐藏操作，保证对等集群的数据一致。</p>
<h2 id="Chain-Base-Index"><a href="#Chain-Base-Index" class="headerlink" title="Chain Base Index"></a>Chain Base Index</h2><p>同时，随着链上 item 数量的不断增加，对 hot item 的内存访问次数可能会线性增长</p>
<p>所以我们需要一个热点感知的hash index</p>
<h2 id="Hotspot-Awareness-challenges"><a href="#Hotspot-Awareness-challenges" class="headerlink" title="Hotspot-Awareness challenges"></a>Hotspot-Awareness challenges</h2><p>用一个 head 指针来指向最热的位置，head 指针能动态指向任意一个 item</p>
<p>为了保证所有 item 的可访问性不受 head 指针的影响，使用有序环结构替换之前的链式结构，这样的环＋head Pointer就可以避免 reorder</p>
<h2 id="Ordered-ring-structure"><a href="#Ordered-ring-structure" class="headerlink" title="Ordered-ring structure"></a>Ordered-ring structure</h2><p>环装结构可能会导致一个问题：之前的链式结构下，如果next是nil那就可以停止查找，但现在是环装结构如果 target item not found，那么可能会无限移动。</p>
<p>所以需要知道什么时候需要结束查找：mark 第一个 item 是不合理的，因为这个 item 可能被并发修改，比如被删除了就会有问题。</p>
<p>可以通过排序，对key进行排序，如果当前移动到的 item 的key比要查找的 item key 大，那么就可以结束查找</p>
<p>为了防止 key 过长导致两个key的比较时间较长，使用了 tag字段。Item 的rank由tag和key共同决定。</p>
<p>Tag 是 hash value 的后 n-k 个bit，前k个bit作为 hashtable part</p>
<h2 id="Identify-hotspots-and-adjust-head-pointer"><a href="#Identify-hotspots-and-adjust-head-pointer" class="headerlink" title="Identify hotspots and adjust head pointer"></a>Identify hotspots and adjust head pointer</h2><p>R的设定影响着响应延迟和热点感知的准确性，R越小，对于热点的感知就会越好，但是这也可能会导致频繁且无效的 head pointer 移动。</p>
<p>但在当前的热点场景下，数据访问呈现非常极端的表现，所以head pointer并不会频繁移动。根据他们的实验 R 为 5 的时候表现最好。</p>
<h2 id="Statistical-Sampling-Strategy"><a href="#Statistical-Sampling-Strategy" class="headerlink" title="Statistical Sampling Strategy"></a>Statistical Sampling Strategy</h2><p>当前 x86-64 的机器下，物理地址只有48位，但是可以通过一个 64 位的 CAS 操作进行更新，那么剩下的 16 位可以用作记录元信息。</p>
<h3 id="Header："><a href="#Header：" class="headerlink" title="Header："></a>Header：</h3><p>active 用来控制热点标识的抽样统计的一个 flag，当 active被set之后，对ring的访问才会被记录在 total counter和相应 item 的counter中。</p>
<h3 id="Item："><a href="#Item：" class="headerlink" title="Item："></a>Item：</h3><p>rehash 用来控制 rehash，这个后面rehash部分会讲到。</p>
<p>occupied 是用来确保并发的正确性的，后面并发操作部分会讲到</p>
<p>每一个线程都有一个 thread-local 变量记录他已经处理的请求数。</p>
<p>如果第 R 个请求是一个 hot access （head pointer指向的是hot item，其他的是 cold item。对hot item的访问就是 hot access），那么不需要进行改变</p>
<p>如果是 cold access，set active，开始计数，因为更新计数需要额外的 CAS 操作，所以我们抽样的数量和环上 item的数量保持一致。</p>
<p>Sampling结束之后一个thread开始计算以第t个item作为head时环的平均内存访问次数Wt，最后选择一个最小Wt的item作为head。（之所以计算环的平均访问次数，是为了适应多热点）</p>
<p>每次更新完head之后重置counter</p>
<h2 id="Concurrent-Operations"><a href="#Concurrent-Operations" class="headerlink" title="Concurrent Operations"></a>Concurrent Operations</h2><p>一方面，头部指针的移动可能与其他线程并发。因此，我们需要考虑头部指针移动和其他修改操作的并发性，以防止指针指向无效项。另一方面，当我们删除或更新项目时，我们需要检查头部指针是否指向该项目。如果是这样，我们需要正确而高效地移动头部指针</p>
<h3 id="RCU（Read-Copy-Update）"><a href="#RCU（Read-Copy-Update）" class="headerlink" title="RCU（Read Copy Update）"></a>RCU（Read Copy Update）</h3><p>适合类似链表的数据结构</p>
<p>读和写不需要额外的同步机制</p>
<p>宽限期 grace period</p>
<p>读多写少</p>
<p>多个写者需要额外的同步策略</p>
<h2 id="Concurrent-Operations-1"><a href="#Concurrent-Operations-1" class="headerlink" title="Concurrent Operations"></a>Concurrent Operations</h2><p>read不牵扯任何并发的问题，按照之前流程读就可以</p>
<p>insert只需要用CAS修改next address就可以</p>
<p>Update时有个问题就是同时有两个 thread，一个在B的后面insert C，一个修改了B。如图a，B的修改使用RCU，C的插入使用CAS，这样可能导致C的失效。</p>
<p>所以我们使用之前说过的一个 occupied bit，当对B进行 Update 之后，B的Occupied就会被set，等到A的nextaddress被更新了之后，对C的insert才会成功因为此时的B’的occupied没有被set</p>
<p>热点转移策略修改的head Pointer，我们会set Occupied，使得在move head 时候不会被Update或修改</p>
<p>如果是 head item发生了update，那么会先 set new item的Occupied，之后move</p>
<p>如果head item 被删除，head item 和 next都被 Occupied</p>
<h2 id="Lock-free-rehash"><a href="#Lock-free-rehash" class="headerlink" title="Lock-free rehash"></a>Lock-free rehash</h2><p>随着不断的 insert，chain的量也越来越大，我们需要根据 data 容量进行 rehash</p>
<p>常见的Rehash的策略是根据 hash table 的链的平均长度触发 rehash，但这没有考虑到热点的影响</p>
<p>新建的hash table是原来的两倍大，新建两个 rehashitem，用 rehash bit 来标记 rehash item</p>
<p>rehash过程分为3步进行，结合上面4图进行说明，图一为哈希表，哈希值在rehash前后的变化。剩余三图为rehash三个过程。</p>
<p>初始化(Initialization)：首先，HotRing创建一个后台rehash线程。该线程创建2倍空间的新哈希表，通过复用tag的最高一位来进行索引。因此，新表中将会有两个头指针与旧表中的一个头指针对应。HotRing根据tag范围对数据进行划分。假设tag最大值为T，tag范围为[0,T)，则两个新的头指针对应tag范围为[0,T&#x2F;2)和[T&#x2F;2,T)。同时，rahash线程创建一个rehash节点(包含两个空数据的子item节点)，子item节点分别对应两个新头指针。HotRing利用item中的Rehash标志位识别rehash节点的子item节点。</p>
<p>分裂(Split)：在分裂阶段，rehash线程通过将rehash节点的两个子item节点插入环中完成环的分裂。如图(Split)所示，因为itemB和E是tag的范围边界，所以子item节点分别插入到itemB和E之前。完成两个插入操作后，新哈希表将激活，所有的访问都将通过新哈希表进行访问。到目前为止，已经在逻辑上将冲突环一分为二。当我们查找数据时，最多只需要扫描一半的item。</p>
<p>删除(Deletion)：删除阶段需要做一些首尾工作，包括旧哈希表的回收。以及rehash节点的删除回收。这里需要强调，分裂阶段和删除阶段间，必须有一个RCU静默期(transition period)。该静默期保证所有从旧哈希表进入的访问均已经返回。否则，直接回收旧哈希表可能导致并发错误。</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Cache</tag>
      </tags>
  </entry>
  <entry>
    <title>In Search of an Understandable Consensus Algorithm (Extended Version)</title>
    <url>/2022/05/15/In-Search-of-an-Understandable-Consensus-Algorithm-Extended-Version/</url>
    <content><![CDATA[<h3 id="Raft特性"><a href="#Raft特性" class="headerlink" title="Raft特性"></a>Raft特性</h3><ul>
<li>强领导者：和其他共识算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。</li>
<li>领导选举：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何共识算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。</li>
<li>关系调整：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法中，两种不同的配置都要求的大多数机器会重叠。这就使得集群在成员变换的时候依然可以继续工作。</li>
</ul>
<span id="more"></span>

<h3 id="Raft设计"><a href="#Raft设计" class="headerlink" title="Raft设计"></a>Raft设计</h3><p><img src="/2022/05/15/In-Search-of-an-Understandable-Consensus-Algorithm-Extended-Version/raft_ele.png"></p>
<p>通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题：</p>
<ul>
<li>领导选举：当先存的领导人宕机的时候，一个新的领导人需要被选举出来</li>
<li>日志复制：领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。</li>
<li>安全性：在 Raft 中安全性的关键是在下表中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。</li>
</ul>
<table>
<thead>
<tr>
<th>特性</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>选举安全特性</td>
<td>对于一个给定的任期号，最多只会有一个领导人被选举出来</td>
</tr>
<tr>
<td>领导人只附加原则</td>
<td>领导人绝对不会删除或者覆盖自己的日志，只会增加</td>
</tr>
<tr>
<td>日志匹配原则</td>
<td>如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同</td>
</tr>
<tr>
<td>领导人完全特性</td>
<td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中</td>
</tr>
<tr>
<td>状态机安全特性</td>
<td>如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志</td>
</tr>
</tbody></table>
<p><img src="/2022/05/15/In-Search-of-an-Understandable-Consensus-Algorithm-Extended-Version/raft_fn.png"></p>
<h3 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h3><p>server使用log中的最新Configuration (未提交也可以)</p>
<p>两个阶段</p>
<ul>
<li><p>joint consensus</p>
<p>新旧Configuration同时存在，commit之后开始propose new Configuration</p>
</li>
<li><p>new configuration</p>
</li>
</ul>
<p>三个可能问题</p>
<ul>
<li><p>新加入的server落后log太多</p>
<p>新加入的server开始作为non-voting成员</p>
</li>
<li><p>当前的leader没有在新Configuration里</p>
<p>复制log时不把自己算到大多数里面</p>
<p>当commit了新Configuration的log之后，leader回退至follower</p>
</li>
<li><p>新Configuration中被移除的节点可能会破坏集群</p>
<p>服务器在认为当前的领导者存在时就不理会RequestVote RPC。如果server在最小选举超时时间内收到leader的heartbeat，它就不会更新其任期或授予其投票权。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>Interesting Golang</title>
    <url>/2022/05/12/Interesting-Golang/</url>
    <content><![CDATA[<p>Golang interesting design</p>
<span id="more"></span>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> A <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(a *A)</span></span> pointerFunc() &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;nil pointer function&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;init1&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">&quot;init2&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo0</span><span class="params">()</span></span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    x := <span class="number">1</span></span><br><span class="line">    f := <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;foo0 val = %d\n&quot;</span>, x)</span><br><span class="line">    &#125;</span><br><span class="line">    x = <span class="number">11</span></span><br><span class="line">    <span class="keyword">return</span> f</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> ap *A</span><br><span class="line">    ap.pointerFunc()</span><br><span class="line"></span><br><span class="line">    val := <span class="number">1997</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">defer</span> fmt.Println(<span class="string">&quot;defer1 val:&quot;</span>, val)</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;defer2 val:&quot;</span>, val)</span><br><span class="line">    &#125;()</span><br><span class="line">    val = <span class="number">1998</span></span><br><span class="line"></span><br><span class="line">    a := [<span class="number">6</span>]<span class="type">int</span>&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line"></span><br><span class="line">    s := a[<span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line">    fmt.Println(a, s)</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">append</span>(s, <span class="number">55</span>)</span><br><span class="line">    fmt.Println(a, s)</span><br><span class="line"></span><br><span class="line">    s[<span class="number">0</span>] = <span class="number">100</span></span><br><span class="line">    fmt.Println(a, s)</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">append</span>(s, <span class="number">6</span>)</span><br><span class="line">    s[<span class="number">0</span>] = <span class="number">1000</span></span><br><span class="line">    fmt.Println(a, s)</span><br><span class="line"></span><br><span class="line">    foo0()()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, v := <span class="keyword">range</span> a &#123;</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            fmt.Println(<span class="string">&quot;goroutine print:&quot;</span>, i, v)</span><br><span class="line">        &#125;()</span><br><span class="line">        v = <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(a)</span><br><span class="line"></span><br><span class="line">    time.Sleep(time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB Primary选举</title>
    <url>/2022/05/12/MongoDB-Primary%E9%80%89%E4%B8%BE/</url>
    <content><![CDATA[<h3 id="副本集简介"><a href="#副本集简介" class="headerlink" title="副本集简介"></a>副本集简介</h3><p>Mongodb副本集由一组Mongod实例（进程）组成，包含一个Primary节点和多个Secondary节点，Mongodb Driver（客户端）的所有数据都写入Primary，Secondary从Primary同步写入的数据，以保持复制集内所有成员存储相同的数据集，提供数据的高可用。副本集带来的架构优点主要有：</p>
<ul>
<li>集群高可用</li>
<li>读写可分离</li>
</ul>
<span id="more"></span>

<ol>
<li><strong>Primary:</strong> 副本集的<strong>主节点</strong>，可读写，<strong>唯一可以进行写操作的节点</strong>，由集群自行选举出来。</li>
<li><strong>Secondary：</strong> 正常情况下，Seconary会参与Primary选举（自身也可能会被选为Primary），并<strong>从Primary同步最新写入的数据</strong>，以保证与Primary存储相同的数据。Secondary<strong>可以提供读服务</strong>，增加Secondary节点可以提供副本集的读服务能力，提升副本集的可用性。</li>
<li><strong>Arbiter：</strong> Arbiter节点<strong>只参与投票</strong>，不能被选为Primary，并且<strong>不从Primary同步数据</strong>。非常轻量级的服务，当复制集成员为偶数时，最好加入一个Arbiter节点，以提升复制集可用性。</li>
<li><strong>Priority0：</strong> Priority0节点的选举优先级为0，<strong>不会被选举为Primary，且不能发起选举</strong>。</li>
<li><strong>Vote0：</strong> 副本集成员最多50个，参与Primary选举投票的成员最多7个，其他成员（Vote0）的vote属性必须设置为0，即<strong>不参与投票</strong>。</li>
<li><strong>Hidden：</strong> Hidden节点不能被选为主（Priority为0），并且<strong>对Driver不可见</strong>。因Hidden节点不会接受Driver的请求，可使用Hidden节点做一些<strong>数据备份、离线计算</strong>的任务，不会影响复制集的服务。</li>
<li><strong>Delayed：</strong> Delayed节点<strong>必须是Hidden节点</strong>，并且其<strong>数据落后与Primary一段时间</strong>（可配置，比如1个小时）。因Delayed节点的数据比Primary落后一段时间，当错误或者无效的数据写入Primary时，可通过Delayed节点来做<strong>数据恢复</strong>。</li>
</ol>
<h3 id="Primary选举"><a href="#Primary选举" class="headerlink" title="Primary选举"></a>Primary选举</h3><p>选举过程需要消耗一些时间，在此期间，集群将不能接收write操作（即使旧的primary仍然存活，但因为“网络分区”问题导致它不能与其他secondaries通讯），所有的members（包括旧的primary）都处于只读状态，选举对业务影响很大，所以需要尽量避免选举的发生。</p>
<p>需要进行Primary选举的场景：</p>
<ol>
<li>副本集初始化时；</li>
<li>副本集被reconfig；</li>
<li>Secondary节点检测到Primary宕机时；</li>
<li>当有Primary节点主动stepDown（主动降级为Secondary）时；</li>
</ol>
<p>Primary的选举受<strong>节点间心跳、优先级、最新的oplog时间</strong>等多种因素影响。</p>
<ol>
<li><strong>心跳：</strong> 复制集中的所有members之间都互相建立心跳连接，且每隔两秒发送一次心跳，如果未在10秒内收到回复，则此member将会被标记为“不可用”，Secondary（前提是可被选为Primary）会发起新的Primary选举，而其他能正常收到心跳反馈的Secondary能否决新的Primary选举。</li>
<li><strong>优先级：</strong> 优先级即Priority值，每个member都有权重值，默认为都为1，members倾向于选举权重最高者。上述提到，priority为0的member不能被选举为primary且不能发起选举；只要当前primary的权重最高或者持有最新oplog数据的secondaries没有比它更高的权重时，集群不会触发选举。当Primary发现有优先级更高Secondary，并且该Secondary的数据落后在10s内，则Primary会主动降级，让优先级更高的Secondary有成为Primary的机会。</li>
<li><strong>Optime：</strong> 当前member已经从primary的oplog中应用的最后一个operation的时间戳（此时间戳由primary生成，在oplog中每个操作记录都有）；一个member能成为primary的首要条件就是在所有有效的members中它持有最新的optime。</li>
<li><strong>多数派连接：</strong> 一个member要成为primary，它必须与“多数派”的其他members建立连接，如果未能与足够多的member建立连接，事实上它本身也无法被选举为primary；多数派参考的是“总票数”，而不是member的个数，因为我们可以给每个member设定不同的“票数”。假设复制集内投票成员数量为N，则大多数为 N&#x2F;2 + 1。</li>
</ol>
<p>综上所述，在发起选举以后，能成为Primary的节点需要的条件有：</p>
<ul>
<li>能够与“多数派”建立连接</li>
<li>在所有有效的members中它持有最新的optime</li>
<li>前两个条件相同的，Priority优先级高的成为Primary</li>
<li>optime与Priority都相等时，谁发起选举，谁当选Primary</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>3.0版本以后<strong>副本集成员最多50个，参与Primary选举投票的成员最多7个</strong>，其他成员（Vote0）的vote属性必须设置为0，即不参与投票。</p>
<p>副本集中各类角色的特点总结如下：</p>
<table>
<thead>
<tr>
<th>节点类型</th>
<th>可读</th>
<th>可写</th>
<th>投票</th>
<th>oplog操作</th>
<th>当选Primary</th>
<th>否决</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>Primary</td>
<td>O</td>
<td>O</td>
<td>O</td>
<td>生成</td>
<td>—</td>
<td>O</td>
<td>无</td>
</tr>
<tr>
<td>Secondary</td>
<td>O</td>
<td>X</td>
<td>O</td>
<td>同步</td>
<td>O</td>
<td>O</td>
<td>常规的Secondary</td>
</tr>
<tr>
<td>Priority&#x3D;0</td>
<td>O</td>
<td>X</td>
<td>O</td>
<td>同步</td>
<td>X</td>
<td>O</td>
<td>无</td>
</tr>
<tr>
<td>Hidden</td>
<td>X</td>
<td>X</td>
<td>O</td>
<td>同步</td>
<td>X</td>
<td>O</td>
<td>Priority&#x3D;0，不可见</td>
</tr>
<tr>
<td>Delayed</td>
<td>X</td>
<td>X</td>
<td>O</td>
<td>同步</td>
<td>X</td>
<td>O</td>
<td>为Hidden，延迟同步</td>
</tr>
<tr>
<td>Arbiter</td>
<td>X</td>
<td>X</td>
<td>O</td>
<td>X</td>
<td>X</td>
<td>O</td>
<td>Priority&#x3D;0，无数据</td>
</tr>
<tr>
<td>vote&#x3D;0</td>
<td>O</td>
<td>X</td>
<td>X</td>
<td>同步</td>
<td>O</td>
<td>O</td>
<td>不能投票</td>
</tr>
</tbody></table>
<p><strong>备注：</strong></p>
<ul>
<li>上述Secondary为默认Secondary，即Priority！&#x3D;0、vote！&#x3D;0等；</li>
<li>Hidden为特殊的Secondary，Delayed为特殊的Hidden</li>
</ul>
]]></content>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>NewSQL 主流实现</title>
    <url>/2022/05/12/NewSQL-%E4%B8%BB%E6%B5%81%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h3 id="NoSQL-ACID-SQL-Layer-x3D-NewSQL"><a href="#NoSQL-ACID-SQL-Layer-x3D-NewSQL" class="headerlink" title="NoSQL+ACID+SQL Layer &#x3D; NewSQL"></a>NoSQL+ACID+SQL Layer &#x3D; NewSQL</h3><p>在独立的KV存储服务上实现事务ACID语义，再通过分层设计在应用层支持文档、图、SQL等多种数据模型</p>
<h3 id="MVCC-OCC-x3D-SSI"><a href="#MVCC-OCC-x3D-SSI" class="headerlink" title="MVCC+OCC&#x3D;SSI"></a>MVCC+OCC&#x3D;SSI</h3><p>基于多版本&#x2F;乐观并发控制技术实现可串行化的快照隔离级别</p>
<h3 id="NewSQL-主流系统"><a href="#NewSQL-主流系统" class="headerlink" title="NewSQL 主流系统"></a>NewSQL 主流系统</h3><p>原生实现</p>
<ul>
<li>CockroachDB</li>
<li>YugaByteDB</li>
</ul>
<p>NoSQL+ACID+SQL</p>
<ul>
<li>TiDB</li>
<li>Trafodion</li>
</ul>
<span id="more"></span>

<p>事务的并发控制是为了实现事务的调度，一个正确、高效的事务调度应满足如下属性：</p>
<ul>
<li>可串行化</li>
</ul>
<p>多个并发事务的调度S与一个串行化的调度产生相同的结果，则称这个调度S是可串行化的。在数据库实现中，一般使用冲突可串行化技术。</p>
<ul>
<li>可恢复性</li>
</ul>
<p>已经提交的事务没有读过被终止的事务写过的数据，防止脏读异常。</p>
<ul>
<li>避免级联终止</li>
</ul>
<p>避免由于事务T1的终止而导致事务T2的终止。</p>
<ul>
<li>严格性</li>
</ul>
<p>先发生写操作的事务的提交或终止应先于其它冲突事务的提交或终止。</p>
<table>
<thead>
<tr>
<th>生产级NewSQL数据库</th>
<th>并发控制</th>
<th>隔离级别</th>
</tr>
</thead>
<tbody><tr>
<td>Spanner</td>
<td>MVCC+SS2PL</td>
<td>Linearizability</td>
</tr>
<tr>
<td>Oceanbase 1.0</td>
<td>MVCC+SS2PL</td>
<td>RC</td>
</tr>
<tr>
<td>CockroachDB 1.0</td>
<td>MVCC+T&#x2F;O</td>
<td>SSI</td>
</tr>
<tr>
<td>TiDB 1.0</td>
<td>MVCC+SS2PL</td>
<td>SI</td>
</tr>
<tr>
<td>FoundationDB 5.1</td>
<td>MVCC+OCC</td>
<td>SSI</td>
</tr>
</tbody></table>
<p>FoundationDB 的 OCC 实现也有一些限制，比如官方文档对 KV 和事务的大小及时长做出了如下限制：</p>
<ul>
<li>key不超过10K；value不超过100K；事务不超过10M（包括所有读、写涉及的KV）</li>
<li>仅支持运行时间不超过5s的读写事务</li>
</ul>
]]></content>
      <tags>
        <tag>OCC</tag>
        <tag>NewSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>OCC 当前研究</title>
    <url>/2022/05/12/OCC-%E5%BD%93%E5%89%8D%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h3 id="内存数据库"><a href="#内存数据库" class="headerlink" title="内存数据库"></a>内存数据库</h3><ul>
<li>随着硬件技术的发展，多核（几十、几百）、大内存（T级别）的单节点配置已在市场上出现，意味着大多数OLTP场景下的数据处理可以完全运行在内存中，SAP HANA、MemSQL、TimesTen、SolidDB、Hekaton等内存数据库也应运而生</li>
<li>关注单机事务吞吐量</li>
</ul>
<h3 id="分布式NewSQL数据库"><a href="#分布式NewSQL数据库" class="headerlink" title="分布式NewSQL数据库"></a>分布式NewSQL数据库</h3><ul>
<li>NoSQL系统虽然实现了承诺的目标，但其不支持SQL语言、缺乏强一致性</li>
<li>既具有NoSQL的所有优点并且还支持SQL语言及ACID事务，如F1、Spanner、CockroachDB、TiDB、OceanBase等</li>
<li>关注分布式事务吞吐量</li>
<li>性能优化目标可以统一描述为在硬件资源充足的情况下如何提高事务吞吐量。节约资源已不再是重点，减少系统同步，提高资源利用率才是核心问题</li>
<li>在分布式计算环境下，网络交互的延迟或异常容易导致2PL协议可能长时间持有锁从而导致系统整体事务吞吐率降低或死锁。</li>
</ul>
<span id="more"></span>

<h3 id="OCC"><a href="#OCC" class="headerlink" title="OCC"></a>OCC</h3><p>优点</p>
<ul>
<li>在高资源竞争、低数据竞争场景下，能够减少事务运行同步开销，避免死锁，支持更高的事务吞吐率</li>
</ul>
<p>缺点</p>
<ul>
<li>在高数据冲突场景下有较高的事务中止率，浪费计算资源（2PL在此场景下事务中止率也很高，但能够提前中止，不用等到事务提交时）</li>
</ul>
<h3 id="在验证阶段使用Paxos提交协议发现冲突"><a href="#在验证阶段使用Paxos提交协议发现冲突" class="headerlink" title="在验证阶段使用Paxos提交协议发现冲突"></a>在验证阶段使用Paxos提交协议发现冲突</h3><h4 id="Megastore-Providing-Scalable-Highly-Available-Storage-for-Interactive-Services-CIDR-2011"><a href="#Megastore-Providing-Scalable-Highly-Available-Storage-for-Interactive-Services-CIDR-2011" class="headerlink" title="Megastore: Providing Scalable, Highly Available Storage for Interactive Services CIDR 2011"></a>Megastore: Providing Scalable, Highly Available Storage for Interactive Services CIDR 2011</h4><p><img src="/2022/05/12/OCC-%E5%BD%93%E5%89%8D%E7%A0%94%E7%A9%B6/megastore.png" alt="Megastore"></p>
<p>Megastore是少有的在内核层实现OCC的生产级分布式数据库系统，在Entity Group的数据分区级别使用MVOCC实现了串行化隔离级别的事务，同一分区一次只能执行一个事务，分布多副本间可以并发执行事务。一个OCC事务三个阶段的实现大致描述如下：</p>
<p>1、读取阶段</p>
<p>① 在任意副本均可发起强一致读；数据更新缓存在应用的事务私有内存</p>
<p>② 从多数派副本中获取最新事务提交时间戳及事务日志的位置（可以通过查询本地coordinator中副本的数据状态做优化）</p>
<p>③ 选择一个合适的副本（综合考虑本地性、响应时间、事务提交时间等），使用Paxos协议同步事务日志并将其应用到本地Bigtable中</p>
<p>④ 若选择了本地副本，则异步更新coordinator中副本数据状态为有效</p>
<p>⑤ 根据获取的事务提交时间戳从本地Bigtable中读取数据</p>
<p>2、验证阶段</p>
<p>① 从强一致读得到的事务日志中获取下一次写入事务日志的位置</p>
<p>② 选取一个比最新事务提交时间戳更大的值作为本次事务提交时间戳</p>
<p>③ 将事务私有内存中的更新打包到一个事务日志中</p>
<p>④ 发起一次完整的两阶段Paxos协议实例（可以优化为一阶段Paxos协议），一个事务日志位置只能由一个事务提交成功。如果成功，则将未成功接受当前事务日志的副本所对应的coordinator中的数据状态设置为失效，通知应用事务已提交；如果失败（prepare阶段发现提交的内容与达成一致的内容不匹配），则终止事务并重新执行</p>
<p>3、写入阶段（异步执行）</p>
<p>将更新数据异步写入Bigtable，清理应用事务私有内存数据</p>
<p><strong>由上述流程可以看出，Megastore将事务局限在一个EG且只能串行化执行，并发冲突的控制粒度在事务级别，导致事务吞吐率非常低。Google内部最终还是放弃了Megastore，转而使用了Spanner（使用MV2PL并发控制技术），因为Spanner通过2PL+2PC实现了跨分区的事务。</strong></p>
<h3 id="MVCC-OCC在内存数据库中的落地"><a href="#MVCC-OCC在内存数据库中的落地" class="headerlink" title="MVCC+OCC在内存数据库中的落地"></a>MVCC+OCC在内存数据库中的落地</h3><h4 id="High-Performance-Concurrency-Control-Mechanisms-for-Main-Memory-Databases-VLDB-2012"><a href="#High-Performance-Concurrency-Control-Mechanisms-for-Main-Memory-Databases-VLDB-2012" class="headerlink" title="High-Performance Concurrency Control Mechanisms for Main-Memory Databases VLDB 2012"></a>High-Performance Concurrency Control Mechanisms for Main-Memory Databases VLDB 2012</h4><p>真正把OCC在生产系统中落地的是内存数据库Hekaton，论文使用全内存的无锁哈希表存储多版本数据，数据的访问全部通过索引查找实现，一个OCC事务的生命周期实现如下：</p>
<p>1正常处理阶段（读取阶段）</p>
<p>① 获取事务开始时的当前时间作为读时间戳并赋予一个唯一的事务号，事务状态设置为active</p>
<p>② 在事务处理的过程中维护读集（指向读版本的指针）、写集（指向写版本的指针）、扫描集（重新执行扫描时需要的信息，如扫描条件）</p>
<p>③ 更新数据时（总在最新的版本上更新），版本可更新的判断：</p>
<ul>
<li>更新数据的end域无效或事务号所属事务已经中止</li>
<li><ul>
<li>将原始版本的end域原子更新为当前事务号，防止其它事务的并发修改</li>
<li>链接新的数据版本并设置begin域为当前事务号</li>
<li>可能会出现更新begin域的事务处于preparing状态的数据版本，采取投机更新策略并记录提交依赖</li>
</ul>
</li>
<li>更新数据的end域事务号所属事务处于active或preparing状态</li>
<li><ul>
<li>写写冲突，更新事务需要中止</li>
</ul>
</li>
</ul>
<p>④ 读取数据时，版本可见性的判断</p>
<ul>
<li>读取数据的begin&#x2F;end域都是有效的时间戳<ul>
<li>如果读时间戳在begin&#x2F;end之间，则可见；否则不可见</li>
</ul>
</li>
<li>读取数据的begin域是事务号<ul>
<li>如果事务号所属的事务状态为active，仅对事务号所属事务可见</li>
<li>如果事务号所属的事务状态为preparing，读时间戳如果比事务提交时间戳大，则采取投机读策略并记录提交依赖（引入了级联中止问题）如果事务号所属的事务状态为aborted，直接忽略</li>
<li>如果事务号所属的事务状态为commited，读时间戳如果比事务提交时间戳大，正常读取</li>
</ul>
</li>
<li>读取数据的end域是事务号<ul>
<li>如果事务号所属的事务状态为active，仅对事务号所属事务不可见</li>
<li>如果事务号所属的事务状态为preparing，读时间戳如果比事务提交时间戳大，则采取投机忽略策略并记录提交依赖（引入了级联中止问题）；读时间戳如果比事务提交时间戳小，则可见</li>
<li>如果事务号所属的事务状态为aborted，可见</li>
<li>如果事务号所属的事务状态为commited，读时间戳如果比事务提交时间戳小，则可见</li>
</ul>
</li>
</ul>
<p>2、准备阶段（验证阶段）</p>
<p>① 获取当前时间戳作为提交时间戳，事务状态设置为preparing</p>
<p>② 读集有效性验证，检查读集中的版本是否依然可见；重新执行扫描集检查是否存在幻读</p>
<p>③ 等待提交依赖全部完成或当前事务是否已被其它事务设置为中止</p>
<p>④ 同步写redo日志</p>
<p>⑤ 将事务状态设置为commited</p>
<p>3、后处理阶段（写入阶段）</p>
<p>① 如果提交，将新数据的begin域和旧数据的end域设置为提交时间戳</p>
<p>② 如果中止，将新数据的begin域设置为无效，尝试将旧数据的end域设置为无效（如果已被其它事务更新则忽略）</p>
<p>③ 处理提交依赖，如果提交，则减少依赖该事务的其它事务的提交依赖计数；如果中止，则通知依赖该事务的其它事务中止</p>
<p>④ 清理事务表</p>
<h3 id="应用层OCC在分布式环境的价值"><a href="#应用层OCC在分布式环境的价值" class="headerlink" title="应用层OCC在分布式环境的价值"></a>应用层OCC在分布式环境的价值</h3><h4 id="F1-A-Distributed-SQL-Database-That-Scales-VLDB-2013"><a href="#F1-A-Distributed-SQL-Database-That-Scales-VLDB-2013" class="headerlink" title="F1: A Distributed SQL Database That Scales VLDB 2013"></a>F1: A Distributed SQL Database That Scales VLDB 2013</h4><p>F1是Google内部研发的分布式关系数据库，存储层基于Spanner，自建SQL层。F1在Spanner之上基于行级的修改时间戳列实现了乐观事务并将其设置为默认配置</p>
<p>优点</p>
<ul>
<li>容忍客户端的不正确行为（如无意义的长事务或未正常结束的事务）</li>
<li>长事务&#x2F;交互式事务友好（没有锁超时导致中止的问题&#x2F;用户查询期间不持有锁）</li>
<li>服务端重试友好，对用户透明</li>
<li>事务更新状态保存在客户端，利于容灾及负载均衡</li>
<li>易于实现投机写（检查读数据的版本变更发现冲突）</li>
</ul>
<p>缺点</p>
<ul>
<li>幻读问题需要借助其它手段避免</li>
<li>高数据竞争场景下的低事务吞吐率</li>
</ul>
<p>其中关于OCC优点的描述来自生产级分布式环境运维的最佳实践经验，虽然只是应用层的简单实现，但也从另一方面验证了OCC在现代分布式数据库环境中的技术价值。</p>
<h3 id="动态调整提交时间戳减少事务中止率"><a href="#动态调整提交时间戳减少事务中止率" class="headerlink" title="动态调整提交时间戳减少事务中止率"></a>动态调整提交时间戳减少事务中止率</h3><h4 id="MaaT-Effective-and-scalable-coordination-of-distributedtransactions-in-the-cloud-VLDB-2014"><a href="#MaaT-Effective-and-scalable-coordination-of-distributedtransactions-in-the-cloud-VLDB-2014" class="headerlink" title="MaaT: Effective and scalable coordination of distributedtransactions in the cloud VLDB 2014"></a>MaaT: Effective and scalable coordination of distributedtransactions in the cloud VLDB 2014</h4><p>当前实现跨结点分布式事务的并发控制技术要么是2PL（Spanner、MySQL Cluster），要么是静态锁（Calvin，对事务操作进行静态分析后提前加锁），而OCC仅在应用层或Megastore中有所应用。OCC没有被普遍使用的原因有如下两点：</p>
<ul>
<li>就适用场景来看，OCC适合于交互式或系统内部组件同步延时较大的场景，而在数据库系统内，磁盘、网络延时通常以毫秒计，OCC导致事务中止浪费计算资源的开销劣势远大于减少同步开销的优势</li>
<li>在分布式数据库实现中，OCC在写入阶段的原子提交协议依然依赖于2PC中的锁机制，没有彻底消除锁机制在云环境中可能会造成的死锁、降低事务吞吐量、系统资源利用率下降等问题</li>
</ul>
<p>但是在云环境下，一个理想的云数据库应该满足如下要求：</p>
<ul>
<li>在长事务、跨结点事务、高数据热点、高通信延时等场景下依然能够支持高事务吞吐率</li>
<li>高效的CPU利用率</li>
<li>高扩展性，减少系统内的同步点</li>
<li>高并发场景下没有系统性能抖动</li>
<li>系统无死锁或永久阻塞点</li>
</ul>
<p>OCC在这种场景下是有技术优势的，因此，论文致力于实现一个消除2PC中的锁机制且大幅降低事务误中止率的分布式数据库系统MaaT，其基本思想如下：</p>
<p><img src="/2022/05/12/OCC-%E5%BD%93%E5%89%8D%E7%A0%94%E7%A9%B6/maat.png" alt="Maat"></p>
<p>基本数据结构</p>
<ul>
<li>在事务访问的每个结点上需要维护内存事务表，记录事务的提交时间戳区间及当前状态（runing&#x2F;validated&#x2F;committed&#x2F;aborted）</li>
<li>每个数据对象维护一个最大读时间戳和最大写时间戳，这些时间戳均为已提交事务的提交时间戳</li>
<li>每个数据对象维护读&#x2F;写过该对象的活跃事务号</li>
</ul>
<p>基本流程</p>
<p>1、读取阶段</p>
<p>① 在事务请求结点上分配一个全局唯一事务号，并在内存事务表中初始化事务信息（提交时间戳区间设置为0到正无穷，状态设置为running）</p>
<p>② 事务执行过程中第一次访问任意远程结点上的数据时都需要在结点本地的内存事务表中建立事务相关初始信息</p>
<p>③ 根据读写类型区别操作</p>
<ul>
<li>读操作</li>
<li>将事务号加入读对象的未提交读事务号列表</li>
<li>返回读对象数据、读对象上当前加写锁的活跃事务号及读对象的最大写时间戳（事务提交时需保证提交时间戳小于所有该对象上写事务的时间戳并大于最大写时间戳）</li>
<li>客户端将返回数据缓存在事务私有内存中</li>
<li>写操作</li>
<li>将更新数据写入客户端的事务私有内存中</li>
</ul>
<p>2、验证阶段</p>
<p>① 客户端发送预写&#x2F;验证消息到所有相关数据服务器（读写涉及到的服务器），消息中包括与服务器相关的读集、写集及在读取阶段从服务器获取的信息（所有在读对象上加写锁的活跃事务号及最大写时间戳）</p>
<p>② 预写（处理服务器上的写操作）</p>
<ul>
<li>收到消息的服务器将事务号加入写对象的未提交写事务列表</li>
<li>写事务日志</li>
<li>获取在写对象上加读锁的活跃事务号及最大读提交时间戳（事务提交时需保证提交时间戳大于所有该对象上读事务的时间戳并大于最大读时间戳）</li>
<li>获取在写对象上加写锁的活跃事务号</li>
</ul>
<p>③ 验证（保证事务的串行化顺序按提交时间戳排序，通过调整事务提交时间戳区间的上下限实现，调整的原则为尽量减少事务中止率）</p>
<ul>
<li>对于读集中的对象，需要保证验证事务能在读对象的最大写时间戳之后提交</li>
<li>对于读对象上的加写锁事务，需要保证在验证事务之后提交</li>
<li>对于写集中的对象，需要保证验证事务在写对象的最大读时间戳之后提交</li>
<li>对于写对象上的加读锁事务，需要保证在验证事务之前提交</li>
<li>对于写对象上的加写锁事务，需要保证在验证事务之后提交</li>
</ul>
<p>④ 验证结束后，如果验证事务的提交时间戳区间有效（下限小于等于上限），则将事务状态改为validated；否则，将事务状态改为aborted</p>
<p>⑤ 各结点通知客户端事务状态及调整后的提交时间戳区间</p>
<p>3、写入阶段</p>
<p>① 如果有结点返回aborted，则事务最终状态为aborted</p>
<p>② 如果所有结点均返回committed，则计算所有提交时间戳区间的交集，区间无效，则事务最终状态为aborted；否则事务最终状态为committed，此时客户端需要从有效区间中选取任意的时间戳作为该事务的提交时间戳</p>
<p>③ 客户端向相关数据结点发送事务提交或中止消息，提交消息中包含更新数据及确定的提交时间戳</p>
<p>④ 对于abort消息，数据结点将本地事务表中的事务状态改为aborted，删除该事务在数据对象上加过的锁并记录事务中止日志</p>
<p>⑤ 对于committed消息，数据结点将本地事务表中的事务状态改为committed，提交时间戳区间设置为客户端确定的时间戳，删除该事务在数据对象上加过的锁并记录事务提交日志</p>
<p>⑥ 对于读集中的数据对象，如果事务提交时间戳大于读对象的最大读时间戳，则将读对象的最大读时间戳设置为事务提交时间戳</p>
<p>⑦ 对于写集中的数据对象，如果事务提交时间戳大于写对象的最大写时间戳，则将写对象的最大写时间戳设置为事务提交时间戳并修改写对象的内容</p>
<p><strong>论文提出的OCC实现方案被2017年的VLDB作为测试OCC性能的参考实现，间接证明这里提出的OCC算法已经得到了学术界的认可，虽然论文中对新OCC算法的性能与其它并发控制算法的比较仍然没有正面评价，但性能瓶颈已经转移到网络传输及CPU计算消耗，事务中止率及同步开销已成为性能瓶颈的次要因素，OCC的扩展性得到了提高。</strong></p>
]]></content>
      <tags>
        <tag>OCC</tag>
      </tags>
  </entry>
  <entry>
    <title>Paper accepted by VLDB 2022</title>
    <url>/2022/04/10/Paper-accepted-by-VLDB-2022/</url>
    <content><![CDATA[<p><strong>Z. Ge</strong>, D. Loghin, B.C. Ooi, P. Ruan, T. Wang: <a href="https://www.comp.nus.edu.sg/~ooibc/hybriddb-vldb22.pdf">Hybrid Blockchain Database Systems: Design and Performance</a>, VLDB 2022.</p>
]]></content>
      <tags>
        <tag>Publication</tag>
      </tags>
  </entry>
  <entry>
    <title>Postgres 现存问题</title>
    <url>/2022/05/25/Postgres-%E7%8E%B0%E5%AD%98%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>原文见 <a href="https://rbranson.medium.com/10-things-i-hate-about-postgresql-20dbab8c2791">10 Things I Hate About PostgreSQL</a></p>
<ol>
<li>灾难性的 XID wrapround<br>XID 是一个32位无符号整数，也就是 XID 的范围是 0到2^32-1；那么超过了 2^32-1的事务怎么办呢？其实 XID 是一个环，超过了 2^32-1 之后又会从头开始分配。需要通过 vacuum 机制来不断的 frozen 元组来回收 XID。<span id="more"></span>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 无效事务号</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> InvalidTransactionId    ((TransactionId) 0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// bootstrap 事务号，在数据库初始化过程（BKI执行）中使用</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BootstrapTransactionId    ((TransactionId) 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// frozen 事务号用于表示非常陈旧的元组，它们比所有正常事务号都要早（也就是可见）</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FrozenTransactionId      ((TransactionId) 2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 第一个正常事务号</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FirstNormalTransactionId  ((TransactionId) 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 把 FullTransactionId 的低32位作为无符号整数生成 xid</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> XidFromFullTransactionId(x)    ((uint32) (x).value)</span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">FullTransactionIdAdvance</span><span class="params">(FullTransactionId *dest)</span></span><br><span class="line">&#123;</span><br><span class="line">dest-&gt;value++;</span><br><span class="line"><span class="keyword">while</span> (XidFromFullTransactionId(*dest) &lt; FirstNormalTransactionId)</span><br><span class="line">    dest-&gt;value++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">FullTransactionId <span class="title function_">GetNewTransactionId</span><span class="params">(<span class="type">bool</span> isSubXact)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">/** ··· **/</span></span><br><span class="line">full_xid = ShmemVariableCache-&gt;nextFullXid;</span><br><span class="line">xid = XidFromFullTransactionId(full_xid);</span><br><span class="line"><span class="comment">/** ··· **/</span></span><br><span class="line">FullTransactionIdAdvance(&amp;ShmemVariableCache-&gt;nextFullXid);</span><br><span class="line"><span class="comment">/** ··· **/</span></span><br><span class="line"><span class="keyword">return</span> full_xid;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">AssignTransactionId</span><span class="params">(TransactionState s)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">/** ··· **/</span></span><br><span class="line">s-&gt;fullTransactionId = GetNewTransactionId(isSubXact);</span><br><span class="line"><span class="keyword">if</span> (!isSubXact)</span><br><span class="line">    XactTopFullTransactionId = s-&gt;fullTransactionId;</span><br><span class="line"><span class="comment">/** ··· **/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">TransactionId <span class="title function_">GetTopTransactionId</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span> (!FullTransactionIdIsValid(XactTopFullTransactionId))</span><br><span class="line">    AssignTransactionId(&amp;TopTransactionStateData);</span><br><span class="line"><span class="keyword">return</span> XidFromFullTransactionId(XactTopFullTransactionId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>Failover 后数据丢失的可能性</li>
<li>低效的 replication 机制</li>
<li>MVCC 带来的 GC 问题（vacuum）</li>
<li>多进程模型</li>
<li>Primary Key Index 的空间浪费</li>
<li>不支持 planner hints<br> 现在可以通过 <a href="https://github.com/ossc-db/pg_hint_plan">pg_hint_plan</a></li>
<li>没有页面压缩（相比于 MySQL 的 innodb）</li>
</ol>
]]></content>
      <tags>
        <tag>Postgres</tag>
      </tags>
  </entry>
  <entry>
    <title>Raft Quiz</title>
    <url>/2022/05/15/Raft-Quiz/</url>
    <content><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><h4 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h4><p>下面的每张图都显示了一台 Raft 服务器上可能存储的日志（日志内容未显示，只显示日志的 index 和任期号）。考虑每份日志都是独立的，下面的日志可能发生在 Raft 中吗？如果不能，请解释原因。</p>
<p><img src="/2022/05/15/Raft-Quiz/raft_q1.png"></p>
<span id="more"></span>

<h4 id="Answer"><a href="#Answer" class="headerlink" title="Answer"></a>Answer</h4><p>a. 不能：任期在日志里必须单调递增。</p>
<p>具体来说，写入日志 &lt;4, 2&gt; 的 Leader1 只能从当前任期 &gt;&#x3D; 3 的 Leader2 那里接收到日志 &lt;3, 3&gt; ，所以 Leader1 当前任期也将 &gt;&#x3D; 3，那么它就不能写入 &lt;4, 2&gt;</p>
<p>b. 可以</p>
<p>c. 可以</p>
<p>d. 不能：日志不允许空洞。 具体来说，Leader 只能追加日志，<code>AppendEntries</code> 中的一致性检查永远不会允许空洞。</p>
<h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><h4 id="Question-1"><a href="#Question-1" class="headerlink" title="Question"></a>Question</h4><p>下图显示了一个 5 台服务器集群中的日志（日志内容未显示）。哪些日志记录可以安全地应用到状态机？请解释你的答案。</p>
<p><img src="/2022/05/15/Raft-Quiz/raft_q2.png"></p>
<h4 id="Answer-1"><a href="#Answer-1" class="headerlink" title="Answer"></a>Answer</h4><p>日志记录 &lt;1,1&gt; 和 &lt;2,1&gt; 可以安全应用（到状态机）：</p>
<p>如果一条日志记录没有存储在多数派上，它就不能被安全地应用。这是因为少数服务器可能故障，并且其它服务器（构成多数派）可以在不知道该日志记录的情况下继续运行。</p>
<p>因此，我们只需要考虑记录 &lt;1,1&gt;, &lt;2,1&gt;, &lt;3,2&gt;, &lt;4,2&gt;, &lt;5,2&gt;。</p>
<p>我们必须弄清楚哪些节点可以当选 Leader，然后看看它们是否会导致这些日志记录被删除。(Leader 处理不一致是通过强 Follower 直接复制自己的日志来解决的)</p>
<p>S2 可以被选为 Leader，因为它的日志至少和 S3、S4 和 S5 一样完整。那么它可能导致 &lt;3,2&gt;, &lt;4,2&gt; 和 &lt;5,2&gt; 被删除，所以这些日志记录不能被安全地应用。</p>
<p>所以我们只剩下 &lt;1,1&gt; 和 &lt;2,1&gt; 可能安全地应用（到状态机）。</p>
<p>S3 和 S4 不能被选为 Leader，因为它们的日志不够完整。S5 能被选举为 LEader，但是它包含了 &lt;1,1&gt; 和 &lt;2,1&gt; 。</p>
<p>因此，只有记录 &lt;1,1&gt; 和 &lt;2,1&gt; 可以被安全地应用（到状态机）</p>
<h3 id="3"><a href="#3" class="headerlink" title="3"></a>3</h3><h4 id="Question-2"><a href="#Question-2" class="headerlink" title="Question"></a>Question</h4><p>考虑下图，它显示了一个 6 台服务器集群中的日志，此时刚刚选出任期 7 的新 Leader（日志内容未显示，只显示日志的 index 和任期号）。对于图中每一个 Follower，给定的日志是否可能在一个正常运行的 Raft 系统中存在？如果是，请描述该情况如何发生的；如果不是，解释为什么。</p>
<p><img src="/2022/05/15/Raft-Quiz/raft_q3.png"></p>
<h4 id="Answer-2"><a href="#Answer-2" class="headerlink" title="Answer"></a>Answer</h4><p>(a) 不能。<strong>如果在不同的日志中的两条记录拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。</strong> &lt;5, 3&gt; 在 Leader 和 a 中都存在，但是前面的日志却不相同。</p>
<p>(b) 不能。同上，&lt;6, 5&gt; 在 Leader 和 b 中都存在，但是前面的日志却不相同。</p>
<p>(c) 可能。c 可能是第 6 任期的 Leader，其起始日志为 &lt;1,1&gt;, &lt;2,1&gt; 并且可能在其日志中写了一堆记录，而没有与我们第 7 任期的当前 Leader 进行通信。这也假设当前 Leader 的 &lt;3,3&gt;、&lt;4,3&gt;、&lt;5,3&gt;、&lt;6,5&gt; 这几个日志记录在第 5 任期没有被写入，这是可能的。</p>
<p>(d) 不能。在一个日志中，任期只能是单调递增的。</p>
<p>(e) 可能。例如，e 是任期 1 的 Leader，提交了日志 &lt;1,1&gt; 和 &lt;2,1&gt;，然后与其它服务器失联（网络分区），但还在继续处理客户端请求。</p>
<h3 id="4"><a href="#4" class="headerlink" title="4"></a>4</h3><h4 id="Question-3"><a href="#Question-3" class="headerlink" title="Question"></a>Question</h4><p>假设硬件或软件错误破坏了 Leader 为某个特定 Follower 存储的 <code>nextIndex</code> 值。这是否会影响系统的安全 ?</p>
<h4 id="Answer-3"><a href="#Answer-3" class="headerlink" title="Answer"></a>Answer</h4><p>不会</p>
<p>如果 <code>nextIndex</code> 的值太小，Leader 将发送额外的 <code>AppendEntries</code> 请求。每个请求都不会对 Follower 的日志产生任何影响（它们将进行一致性检查，但不会和 Follower 日志中的记录产生冲突，也不会向 Follower 提供该 Follower 没有存储的任何日志记录），成功的响应将告诉 Leader 应该增加其 <code>nextIndex</code>。</p>
<p>如果 <code>nextIndex</code> 的值太大，Leader 也将发送额外的 <code>AppendEntries</code> 请求，对此，一致性检查将会失败，从而导致 Follower 拒绝该请求，Leader 将会递减 <code>nextIndex</code> 值并重试。</p>
<p>无论哪种方式，这都是安全的行为，因为两种情况下都不会修改关键的状态。</p>
<h3 id="5"><a href="#5" class="headerlink" title="5"></a>5</h3><h4 id="Question-4"><a href="#Question-4" class="headerlink" title="Question"></a>Question</h4><p>假设你实现了 Raft，并将它部署在同一个数据中心的所有服务器上。现在假设你要将系统部署到分布在世界各地的不同数据中心的每台服务器，与单数据中心版本相比，多数据中心的 Raft 需要做哪些更改？为什么？</p>
<h4 id="Answer-4"><a href="#Answer-4" class="headerlink" title="Answer"></a>Answer</h4><p>我们需要将选举超时(election timeouts)时间设置得更长：预期的广播时间更长，选举超时时间应该比广播时间长得多，以便候选人有机会在再次超时之前完成一次选举。该算法其余部分不需要任何修改，因为它不依赖于时序。</p>
<h3 id="6"><a href="#6" class="headerlink" title="6"></a>6</h3><h4 id="Question-5"><a href="#Question-5" class="headerlink" title="Question"></a>Question</h4><p>每个 Follower 都在其磁盘上存储了 3 个信息：当前任期（<code>currentTerm</code>）、最近的投票（<code>votedFor</code>）、以及所有接受的日志记录（<code>log[]</code>）。</p>
<p>a. 假设 Follower 崩溃了，并且当它重启时，它最近的投票信息已丢失。该 Follower 重新加入集群是否安全（假设未对算法做任何修改）？解释一下你的答案。</p>
<p>b. 现在，假设崩溃期间 Follower 的日志被截断（truncated）了，日志丢失了最后的一些记录。该 Follower 重新加入集群是否安全（假设未对算法做任何修改）？解释一下你的答案。</p>
<h4 id="Answer-5"><a href="#Answer-5" class="headerlink" title="Answer"></a>Answer</h4><p>a. 不安全。这将允许一个服务器在同一任期内投票两次，这样以来，每个任期就可以有多个 Leader 参与，这几乎破坏了一切。</p>
<p>例如，对于 3 台服务器：</p>
<ul>
<li>S1 获得 S1 和 S2 的投票，并且成为任期 2 的 Leader</li>
<li>S2 重启，丢失了它在任期 2 中投过的票(votedFor)</li>
<li>S3 获得 S2 和 S3 的选票，并且成为任期 2 的第二任 Leader</li>
<li>现在 S1 和 S3 都可以在任期 2 同一 index 的日志记录上提交不同的值。</li>
</ul>
<p>b. 不安全。这将允许已提交的日志不被存储在多数派上，然后将允许同一 index 提交其它不同的值。 例如，对于 3 台服务器：</p>
<ul>
<li>S1 成为任期 2 的 Leader，并在自己和 S2 上追加写了 index&#x3D;1, term&#x3D;2, value&#x3D;X，并设置 committedIndex&#x3D;1，然后返回已提交的值 X 给客户端</li>
<li>S2 重启，并且丢失了其日志中的记录</li>
<li>S3（具有空的日志）成为任期 3 的 Leader，因为它的空日志也至少与 S2 一样完整。S3 在自己和 S2 上追加写 index&#x3D;1, term&#x3D;3, value&#x3D;Y，并设置committedIndex&#x3D;1，然后返回已提交的值 Y 给客户端</li>
</ul>
<h3 id="7"><a href="#7" class="headerlink" title="7"></a>7</h3><h4 id="Question-6"><a href="#Question-6" class="headerlink" title="Question"></a>Question</h4><p>如<a href="https://www.youtube.com/watch?v=YbZ3zDzDnrw">视频</a>中所述，即使其它服务器认为 Leader 崩溃并选出了新的 Leader 后，（老的）Leader 依然可能继续运行。新的 Leader 将与集群中的多数派联系并更新它们的任期，因此，老的 Leader 将在与多数派中的任何一台服务器通信后立即下台。然而，与此期间，它也可以继续充当 Leader，并向尚未被新 Leader 联系到的 Follower 发出请求；此外，客户端可以继续向老的 Leader 发送请求。我们知道，在选举结束后，老的 Leader 不能提交（commit）任何<strong>新的</strong>日志记录，因为这样做需要联系选举多数派中的至少一台服务器。但是，老的 Leader 是否有可能执行一个成功 <code>AppendEntries RPC</code>，从而完成在选举开始前收到的旧日志记录的提交？如果可以，请解释这种情况是如何发生的，并讨论这是否会给 Raft 协议带来问题。如果不能发生这种情况，请说明原因。</p>
<h4 id="Answer-6"><a href="#Answer-6" class="headerlink" title="Answer"></a>Answer</h4><p>可能。仅当新 Leader 也包含正在提交的日志时，才会发生这种情况，所以不会引起问题。</p>
<p>下面是一个在 5 台服务器发生这种情况的例子：</p>
<ul>
<li>带有空日志的 S1 成为任期 2 的 Leader，票选来自 S1，S2 和 S3</li>
<li>S1 将 index&#x3D;1, term&#x3D;2, value&#x3D;X 追加写到它自己和 S2</li>
<li>S2 的日志中包含 index&#x3D;1, term&#x3D;2, value&#x3D;X，S2 成为任期 3 的 Leader，票选来自 S2，S4 和 S5</li>
<li>S1 将 index&#x3D;1, term&#x3D;2, value&#x3D;X 追加写到 S3</li>
<li>此时，S1 已经完成了对 index&#x3D;1, term&#x3D;2, value&#x3D;X 的提交，即使它不再是当前任期的 Leader</li>
</ul>
<p>这种行为是安全的，因为任何新的 Leader 也必须包含该日志记录，因此它将永远存在。</p>
<p>该日志记录必须存储在给新 Leader（记为 L）投票的服务器 S 上，并且必须在 S 给新 Leader 投票之前存储在 S 上，日志完整性会检测，S 只能在以下情况投票给 L： <code>L.lastLogTerm &gt; S.lastLogTerm</code> 或者 <code>(L.lastLogTerm == S.lastLogTerm and L.lastLogIndex &gt;= S.lastLogIndex)</code></p>
<p>如果 L 是 S 之后的第一任 Leader，那么我们必须处于第二个条件下，那么 L 一定包含了 S 拥有的所有日志记录，包括我们担心的那个记录。</p>
<p>如果 L’ 是 S 之后的第二任 Leader，那么 L’ 只有从 L 那里接收到了日志，它最新的任期号才可能比 S 大。但是 L 在把自己的日志复制到 L’ 时也一定已经把我们担心的那条日志复制到 L’ 了，所以这也是安全的。</p>
<p>而且，这个论点对未来所有的 Leader 都成立。</p>
<h3 id="8"><a href="#8" class="headerlink" title="8"></a>8</h3><h4 id="Question-7"><a href="#Question-7" class="headerlink" title="Question"></a>Question</h4><p>在配置变更过程中，如果当前 Leader 不在 C-new 中，一旦 C-new 的日志记录被提及，它就会下台。然而，这意味着有一段时间，Leader 不属于它所领导的集群（Leader 上存储的当前配置条目是 C-new，它不包括 Leader）。假设修改算法，如果 C-new 不包含 Leader，则使 Leader 在其日志存储了 C-new 时就立即下台。这种方法可能发生的最坏情况是什么？</p>
<h4 id="Answer-7"><a href="#Answer-7" class="headerlink" title="Answer"></a>Answer</h4><p>答案 1: 假设一个不错的实现——一旦一个服务器不再属于其当前配置，它就不会再成为 Candidate。问题在于，C-old 中的另一台服务器可能会被选为 Leader，在其日志中追加 C-new，然后立即下台。</p>
<p>更糟糕的是，这种情况可能会在 C-old 的多数派服务器上重复。一旦超过半数 C-old 存储了 C-new 条目，它就不能再重复了。由于日志完整性检查，没有 C-new 这条日志记录的 C-old 中的任何服务器都不能当选（超过半数的 C-old 需要日志 C-old+new，不会再给没有 C-new 这条日志记录的服务器投票。）</p>
<p>在这之后，C-new 中的某台服务器必须当选，集群就会继续运行。所以最坏的情况其实只是跑了<strong>最多</strong>大约 |C-old|&#x2F;2 次额外的选举和选举超时。</p>
<p>答案 2: 假设一个朴素的（naive）实现，仍允许一个不属于其当前配置的服务器成为 Candidate，在这种情况下，最坏的情况是， Leader 一下台就再次当选（它的日志仍然是完整的），然后再下台，然后无限重复。</p>
]]></content>
      <tags>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>TKDE Reviewer Invitation</title>
    <url>/2022/05/10/TKDE-Reviewer-Invitation/</url>
    <content><![CDATA[<p><strong>TKDE</strong>(IEEE Transactions on Knowledge and Data Engineering) Reviewer <a href="https://publons.com/researcher/5190849/zerui-ge/">https://publons.com/researcher/5190849/zerui-ge/</a></p>
]]></content>
      <tags>
        <tag>Publication</tag>
      </tags>
  </entry>
  <entry>
    <title>UUID</title>
    <url>/2022/05/15/UUID/</url>
    <content><![CDATA[<h3 id="UUID-特点"><a href="#UUID-特点" class="headerlink" title="UUID 特点"></a>UUID 特点</h3><ul>
<li><p>经由一定的算法机器生成<br>为了保证UUID的唯一性，规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。</p>
</li>
<li><p>非人工指定，非人工识别<br>UUID是不能人工指定的，除非你冒着UUID重复的风险。UUID的复杂性决定了“一般人“不能直接从一个UUID知道哪个对象和它关联。</p>
</li>
<li><p>在特定的范围内重复的可能性极小<br>UUID的生成规范定义的算法主要目的就是要保证其唯一性。但这个唯一性是有限的，只在特定的范围内才能得到保证，这和UUID的类型有关（参见UUID的版本）。</p>
</li>
</ul>
<span id="more"></span>

<h3 id="Nil-UUID"><a href="#Nil-UUID" class="headerlink" title="Nil UUID"></a>Nil UUID</h3><p>通常我们不会用到它，它是由全为0的数字组成，如下：<br>00000000-0000-0000-0000-000000000000</p>
<h3 id="UUID-Version-1：基于时间的UUID"><a href="#UUID-Version-1：基于时间的UUID" class="headerlink" title="UUID Version 1：基于时间的UUID"></a>UUID Version 1：基于时间的UUID</h3><p>基于时间的UUID通过计算当前时间戳、随机数和机器MAC地址得到。由于在算法中使用了MAC地址，这个版本的UUID可以保证在全球范围的唯一性。但与此同时，使用MAC地址会带来安全性问题，这就是这个版本UUID受到批评的地方。如果应用只是在局域网中使用，也可以使用退化的算法，以IP地址来代替MAC地址－－Java的UUID往往是这样实现的（当然也考虑了获取MAC的难度）。</p>
<h3 id="UUID-Version-2：DCE安全的UUID"><a href="#UUID-Version-2：DCE安全的UUID" class="headerlink" title="UUID Version 2：DCE安全的UUID"></a>UUID Version 2：DCE安全的UUID</h3><p>DCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。</p>
<h3 id="UUID-Version-3：基于名字的UUID（MD5）"><a href="#UUID-Version-3：基于名字的UUID（MD5）" class="headerlink" title="UUID Version 3：基于名字的UUID（MD5）"></a>UUID Version 3：基于名字的UUID（MD5）</h3><p>基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。</p>
<h3 id="UUID-Version-4：随机UUID"><a href="#UUID-Version-4：随机UUID" class="headerlink" title="UUID Version 4：随机UUID"></a>UUID Version 4：随机UUID</h3><p>根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但随机的东西就像是买彩票：你指望它发财是不可能的，但狗屎运通常会在不经意中到来。</p>
<h3 id="UUID-Version-5：基于名字的UUID（SHA1）"><a href="#UUID-Version-5：基于名字的UUID（SHA1）" class="headerlink" title="UUID Version 5：基于名字的UUID（SHA1）"></a>UUID Version 5：基于名字的UUID（SHA1）</h3><p>和版本3的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。</p>
<h3 id="UUID-应用"><a href="#UUID-应用" class="headerlink" title="UUID 应用"></a>UUID 应用</h3><p>Version 1&#x2F;2 适合应用于分布式计算环境下，具有高度的唯一性。<br>Version 3&#x2F;5 适合于一定范围内名字唯一，且需要或可能会重复生成UUID的环境下。<br>Version 4 是最简单最方便的，理论碰撞概率非常低。</p>
<p>通常使用 UUID Version 4，只有在需要特殊性质的时候选择别的：</p>
<ul>
<li>可按时间排序（<a href="https://github.com/ulid/spec">ULID 1</a> )</li>
<li>encode 特殊信息（feature store &#x2F; seaweed id）</li>
<li>长度&#x2F;编码效率（<a href="https://blog.twitter.com/engineering/en_us/a/2010/announcing-snowflake.html">Twitter Snowflake 2</a>）</li>
</ul>
<p>UUID 一般来标识对象或持久化数据，但以下情况最好不使用UUID：</p>
<ul>
<li><p>映射类型的对象。比如只有代码及名称的代码表。</p>
</li>
<li><p>人工维护的非系统生成对象。比如系统中的部分基础数据。</p>
</li>
<li><p>对于具有名称不可重复的自然特性的对象，最好使用 Version 3&#x2F;5 的 UUID。比如系统中的用户。如果用户的 UUID 是 Version 1 的，如果你不小心删除了再重建用户，你会发现人还是那个人，用户已经不是那个用户了。（虽然标记为删除状态也是一种解决方案，但会带来实现上的复杂性。）</p>
</li>
</ul>
<h3 id="Twitter-Snowflake"><a href="#Twitter-Snowflake" class="headerlink" title="Twitter Snowflake"></a>Twitter Snowflake</h3><p>Twitter-Snowflake 算法产生的背景相当简单，为了满足Twitter每秒上万条消息的请求，每条消息都必须分配一条唯一的id，这些id还需要一些大致的顺序（方便客户端排序），并且在分布式系统中不同机器产生的id必须不同。</p>
<h4 id="Snowflake算法核心"><a href="#Snowflake算法核心" class="headerlink" title="Snowflake算法核心"></a>Snowflake算法核心</h4><p>把<strong>时间戳</strong>，<strong>工作机器id</strong>，<strong>序列号</strong>组合在一起。</p>
<p>无用（1bit）+ 时间戳（41bit）+ 工作机器ID（10bit）+ 序列号（12bit）</p>
<p>除了最高位bit标记为不可用以外，其余三组bit占位均可浮动，看具体的业务需求而定。<strong>默认情况下41bit的时间戳可以支持该算法使用到2082年，10bit的工作机器id可以支持1023台机器，序列号支持1毫秒产生4095个自增序列id</strong>。</p>
<h4 id="Snowflake-–-时间戳"><a href="#Snowflake-–-时间戳" class="headerlink" title="Snowflake – 时间戳"></a>Snowflake – 时间戳</h4><p>这里时间戳的细度是毫秒级，具体代码如下，建议使用64位linux系统机器，因为有<a href="http://man7.org/linux/man-pages/man7/vdso.7.html">vdso</a>，gettimeofday()在用户态就可以完成操作，减少了进入内核态的损耗。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">uint64_t</span> <span class="title">generateStamp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    timeval tv;</span><br><span class="line">    <span class="built_in">gettimeofday</span>(&amp;tv, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> (<span class="type">uint64_t</span>)tv.tv_sec * <span class="number">1000</span> + (<span class="type">uint64_t</span>)tv.tv_usec / <span class="number">1000</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>默认情况下有41个bit可以供使用，那么一共有T（2 ^ 41）毫秒供你使用分配，年份 &#x3D; T &#x2F; (3600 * 24 * 365 * 1000) &#x3D; 69.7年。如果你只给时间戳分配39个bit使用，那么根据同样的算法最后年份 &#x3D; 17.4年。</p>
<h4 id="Snowflake-–-工作机器id"><a href="#Snowflake-–-工作机器id" class="headerlink" title="Snowflake – 工作机器id"></a>Snowflake – 工作机器id</h4><p>严格意义上来说这个bit段的使用可以是进程级，<strong>机器级的话你可以使用MAC地址来唯一标示工作机器</strong>，<strong>工作进程级可以使用IP+Path来区分工作进程</strong>。如果工作机器比较少，可以使用配置文件来设置这个id是一个不错的选择，如果机器过多配置文件的维护是一个灾难性的事情。</p>
<p>这里的解决方案是需要一个工作id分配的进程，可以使用自己编写一个简单进程来记录分配id，或者利用Mysql auto_increment机制也可以达到效果。</p>
<p>工作进程与工作id分配器只是在工作进程启动的时候交互一次，然后工作进程可以自行将分配的id数据落文件，下一次启动直接读取文件里的id使用。</p>
<p>PS：这个工作机器id的bit段也可以进一步拆分，比如用前5个bit标记进程id，后5个bit标记线程id之类。</p>
<h4 id="Snowflake-–-序列号"><a href="#Snowflake-–-序列号" class="headerlink" title="Snowflake – 序列号"></a>Snowflake – 序列号</h4><p>序列号就是一系列的自增id（多线程建议使用atomic），为了处理在同一毫秒内需要给多条消息分配id，若同一毫秒把序列号用完了，则“等待至下一毫秒”。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">uint64_t</span> <span class="title">waitNextMs</span><span class="params">(<span class="type">uint64_t</span> lastStamp)</span> </span>&#123;</span><br><span class="line">    <span class="type">uint64_t</span> cur = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        cur = <span class="built_in">generateStamp</span>();</span><br><span class="line">    &#125; <span class="keyword">while</span> (cur &lt;= lastStamp);</span><br><span class="line">    <span class="keyword">return</span> cur;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>总体来说，是一个很高效很方便的GUID产生算法，一个int64_t字段就可以胜任，不像现在主流128bit的GUID算法，即使无法保证严格的id序列性，但是对于特定的业务，比如用做游戏服务器端的GUID产生会很方便。另外，在多线程的环境下，序列号使用atomic可以在代码实现上有效减少锁的密度。</p>
]]></content>
      <tags>
        <tag>Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>Varint</title>
    <url>/2022/05/15/Varint/</url>
    <content><![CDATA[<h3 id="Varint-编码原理"><a href="#Varint-编码原理" class="headerlink" title="Varint 编码原理"></a>Varint 编码原理</h3><p>除了最后一个字节外，varint 编码中的每个字节都设置了最高有效位 (most significant bit - msb)</p>
<p>msb 为 1 则表明后面的字节还是属于当前数据的, 如果是 0 那么这是当前数据的最后一个字节数据。</p>
<p>每个字节的低7位用于以7位为一组存储数字的二进制补码表示，最低有效组在前，或者叫最低有效字节在前。这表明varint编码后数据的字节是按照<strong>小端序</strong>排列的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">十进制: 123456</span><br><span class="line">二进制补码: 111 1000100 1000000</span><br><span class="line">Varint 编码: 11000000 11000100 0000111</span><br></pre></td></tr></table></figure>
<span id="more"></span>

<h3 id="Golang-实现"><a href="#Golang-实现" class="headerlink" title="Golang 实现"></a>Golang 实现</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> maxVarintBytes = <span class="number">10</span> <span class="comment">// maximum length of a varint</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回Varint类型编码后的字节流</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">EncodeVarint</span><span class="params">(x <span class="type">uint64</span>)</span></span> []<span class="type">byte</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> buf [maxVarintBytes]<span class="type">byte</span></span><br><span class="line">    <span class="keyword">var</span> n <span class="type">int</span></span><br><span class="line">    <span class="comment">// 下面的编码规则需要详细理解:</span></span><br><span class="line">    <span class="comment">// 1.每个字节的最高位是保留位, 如果是1说明后面的字节还是属于当前数据的,如果是0,那么这是当前数据的最后一个字节数据</span></span><br><span class="line">    <span class="comment">//  看下面代码,因为一个字节最高位是保留位,那么这个字节中只有下面7bits可以保存数据</span></span><br><span class="line">    <span class="comment">//  所以,如果x&gt;127,那么说明这个数据还需大于一个字节保存,所以当前字节最高位是1,看下面的buf[n] = 0x80 | ...</span></span><br><span class="line">    <span class="comment">//  0x80说明将这个字节最高位置为1, 后面的x&amp;0x7F是取得x的低7位数据, 那么0x80 | uint8(x&amp;0x7F)整体的意思就是</span></span><br><span class="line">    <span class="comment">//  这个字节最高位是1表示这不是最后一个字节,后面7为是正式数据! 注意操作下一个字节之前需要将x&gt;&gt;=7</span></span><br><span class="line">    <span class="comment">// 2.看如果x&lt;=127那么说明x现在使用7bits可以表示了,那么最高位没有必要是1,直接是0就ok!所以最后直接是buf[n] = uint8(x)</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// 如果数据大于一个字节(127是一个字节最大数据), 那么继续, 即: 需要在最高位加上1</span></span><br><span class="line">    <span class="keyword">for</span> n = <span class="number">0</span>; x &gt; <span class="number">127</span>; n++ &#123;</span><br><span class="line">        <span class="comment">// x&amp;0x7F表示取出下7bit数据, 0x80表示在最高位加上1</span></span><br><span class="line">        buf[n] = <span class="number">0x80</span> | <span class="type">uint8</span>(x&amp;<span class="number">0x7F</span>)</span><br><span class="line">        <span class="comment">// 右移7位, 继续后面的数据处理</span></span><br><span class="line">        x &gt;&gt;= <span class="number">7</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 最后一个字节数据</span></span><br><span class="line">    buf[n] = <span class="type">uint8</span>(x)</span><br><span class="line">    n++</span><br><span class="line">    <span class="keyword">return</span> buf[<span class="number">0</span>:n]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DecodeVarint</span><span class="params">(buf []<span class="type">byte</span>)</span></span> (x <span class="type">uint64</span>, n <span class="type">int</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> shift := <span class="type">uint</span>(<span class="number">0</span>); shift &lt; <span class="number">64</span>; shift += <span class="number">7</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> n &gt;= <span class="built_in">len</span>(buf) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">        b := <span class="type">uint64</span>(buf[n])</span><br><span class="line">        n++</span><br><span class="line">    <span class="comment">// 下面这个分成三步走:</span></span><br><span class="line">        <span class="comment">// 1: b &amp; 0x7F 获取下7bits有效数据</span></span><br><span class="line">        <span class="comment">// 2: (b &amp; 0x7F) &lt;&lt; shift 由于是小端序, 所以每次处理一个Byte数据, 都需要向高位移动7bits</span></span><br><span class="line">        <span class="comment">// 3: 将数据x和当前的这个字节数据 | 在一起</span></span><br><span class="line">        x |= (b &amp; <span class="number">0x7F</span>) &lt;&lt; shift</span><br><span class="line">        <span class="keyword">if</span> (b &amp; <span class="number">0x80</span>) == <span class="number">0</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> x, n</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The number is too large to represent in a 64-bit value.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Engineering</tag>
      </tags>
  </entry>
  <entry>
    <title>WiscKey: Separating Keys from Values in SSD-conscious Storage</title>
    <url>/2022/05/15/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/</url>
    <content><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>这篇 Paper 将的都是如何解决 LSM-Tree 的写放大的问题。Wisckey的基本思路其实很简单，使用的方法就是将Key和Value分开保存的方式，对于读取Value时造成的随机读写问题，Wisckey则认为这个在SSD上的问题能得到缓解，也使用了预取，并行读等的一些优化方式。在SOSP‘17上面的 PebblesDB 则对 LSM-Tree 的结构进行了比较好的改进，个人认为这个是一种更加好的方式。WiscKey的设计目标是为随机性能比较好的SSD优化的，因为它的设计会导致比较多的随机读，它在测试数据中实现了,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">We demonstrate the advantages of WiscKey with both microbenchmarks and YCSB workloads. Microbenchmark results show that WiscKey is 2.5×–111× faster than LevelDB for loading a database and 1.6×–14× faster for random lookups. WiscKey is faster than both LevelDB and RocksDB in all six YCSB workloads.</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h3 id="Key-Value-Separation"><a href="#Key-Value-Separation" class="headerlink" title="Key-Value Separation"></a>Key-Value Separation</h3><p>WiscKey的核心思路基本就是将Key-Value分开保存了。在LSM-Tree中，每次merge的操作会造成写放大的问题，但如果将里面的Value拿出来分开保存，直接保存在LSM-Tree的数据就减小很多，因为一般情况下，Key的尺寸远小于Value的尺寸。直接在LSM-Tree就只需要保存Value的地址信息。这个思路和bitcask的思路很相似。不同点：bitcask的索引结构一般为hash table，当然使用skip list之类的数据结构也完全是可以的；另外一个不同点就是bitcask的索引都是全部保存在内存里面的，也会定期的持久化到磁盘上面。</p>
<p><img src="/2022/05/15/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/wisckey_1.png" alt="Wisckey Data Layout on SSD"></p>
<p>如上图所示，Key Values-Address的pair保存在LSM-Tree里面，而Value本身就保存在类似Log的结构里面。由于Key Value之间很大的尺寸差异，这样LSM-Tree里面实际保存的数据就会大大减小，也就能很大程度上解决写入放大的问题:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">For example, assuming a 16-B key, a 1KB value, and a write amplification of 10 for keys (in the LSM-tree) and 1 for values, the effective write amplification of WiscKey is only (10 × 16 + 1024) / (16 + 1024) = 1.14. In addition to improving the write performance of applications, the reduced write amplification also improves an SSD’s lifetime by requiring fewer erase cycles.</span><br></pre></td></tr></table></figure>

<h3 id="要解决的问题"><a href="#要解决的问题" class="headerlink" title="要解决的问题"></a>要解决的问题</h3><ul>
<li><p>Parallel Range Query，这是WiscKey要处理的一个最主要的问题，范围查询对于LevelDB之类的将Key和Value放在一起的设计来说，这个做起来就很简单。对于WiscKey来说，这就因为着会产生大量的随机读操作，当然就会影响到性能。这里WiscKey的拒绝办法是利用SSD设备的并行IO的能力，对于范围查询，WiscKey对Next() or Prev() 的请求，会分析访问的模式，一旦一个发现是一个连续的顺序访问，WiscKey就会读取画面的若干的Key，然后并发的使用这些Key信息去取回Value。</p>
</li>
<li><p>Garbage Collection，一般的LSM-Tree的设计垃圾回收是在compaction的时候进行的，对于WiscKey来说，这里要处理的问题是，直接扫描Value Log(vLog)处理的方式是不好的，会带来太大的overhead。未来解决这个问题，这里处理的方式是对WiscKey的Data Layout进行少许的修改，在vLog里面不仅仅是保存了数据，而是以这样的方式保存<code>(key size, value size, key, value) </code>。WiscKey的垃圾回收的一个目标就是将有效的Value保存在一个连续的范围之内。如下面的图所示，在vLog里面，有一个head代表了写入的位置，一个tail代表了垃圾回收要处理的开始的位置。垃圾回收的是，WsicKey先读区几个MB的数据，检查里面合法的数据，然后将这些数据写入到head。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">To avoid losing any data if a crash happens during garbage collection, WiscKey has to make sure that the newly appended valid values and the new tail are persistent on the device before actually freeing space.</span><br></pre></td></tr></table></figure>
</li>
<li><p>Crash Consistency，即使这里Key Value是分开保存的，WiscKey依然可以提供Crash Consistency。在系统崩溃的时候可能出现只有一部分的数据被append的vLog的后面，也可以保存如果Value X在carsh中丢失了，后面的数据也都会丢失，不会出现随机的一些bytes or 不是Value前缀的数据被添加进去。当查询是，WiscKey如果发现一个Key在LSM-Tree中发现不了，就会认为这个数据在Carsh中丢失了。如果能在LSM-Tree中被发现，则会检查数据的合法性，如果检查不通过，就会认为这个Value在Crash中被丢失了，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">In this case, WiscKey first verifies whether the value address retrieved from the LSM-tree falls within the current valid range of the vLog, and then whether the value found corresponds to the queried key. If the verifications fail, WiscKey assumes that the value was lost during a system crash, deletes the key from the LSM- tree, and informs the user that the key was not found.</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="/2022/05/15/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/wisckey_2.png" alt="Wisckey New Data Layout for GC"></p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><ul>
<li><p>Value-Log Write Buffer，这个优化是一个显而易见的优化，资额vLog的时候最好就是积攒了一些数据之后在写入到文件里面。添加了这个write buffer之后，要添加的一个处理就是查找的时候要先查找这个buffer里面的数据，因为这里的数据还是在内存里面的。</p>
</li>
<li><p>Optimizing the LSM-tree Log，这也是一个很好的优化，前面提到的在vLog里面的数据是既有Value也有Key的，这样的话就不用在额外使用Log了。为了加快Crash之后的恢复的速度，WiscKey周期性的在vLog的head里面添加一个<code>&lt;‘‘head’’, head-vLog-offset&gt;</code>，这个就类似于一个checkpoint的机制，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">WiscKey records the head of the vLog periodically in the LSM-tree, as a key-value pair &lt;‘‘head’’, head-vLog-offset&gt;. When a database is opened, WiscKey starts the vLog scan from the most recent head position stored in the LSM-tree, and continues scanning until the end of the vLog. Since the head is stored in the LSM-tree, and the LSM-tree inherently guarantees that keys inserted into the LSM-tree will be recovered in the inserted order, this optimization is crash consistent.</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>基本的性能数据(详细的数据参看论文):</p>
<p><img src="/2022/05/15/WiscKey-Separating-Keys-from-Values-in-SSD-conscious-Storage/wisckey_3.png" alt="Wisckey Performance"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这个在一些随机性能非常好的SSD上面是一种非常有效的办法。对于现在的很多NVMe的SSD来说，4K的随机性能以及是几十万的基本了。这个办法的优势在于它的简单，而且很有效。另外，感觉这里的写入和垃圾回收还是可以有优化的空间的。</p>
]]></content>
      <tags>
        <tag>Paper</tag>
        <tag>LSM</tag>
      </tags>
  </entry>
  <entry>
    <title>bug of Golang httputil.ReverseProxy</title>
    <url>/2022/05/12/bug-of-Golang-httputil-ReverseProxy/</url>
    <content><![CDATA[<p><code>writeLoop</code> and <code>readLoop</code> 使用同一个 conn。在 <code>readLoop</code> 出错时，会将 close conn，但是 <code>writeLoop</code> 不一定会及时捕获到这个信息，导致 <code>writeLoop</code> 继续往一个已经为 <code>nil</code> 的 bufWriter 写东西，从而 panic。</p>
<span id="more"></span>

<p>I construct a broken server. The server will always send 100-continue and an incorrect header to proxy. In ReverseProxy，transport.RoundTrip(outreq) will receive an error and don’t keep the connection to client. After the connection is closed, (*conn).finalFlush will assign (*conn).bufw &#x3D; nil. At the same time, writeLoop probably doesn’t exit and may writeBody. The body here is an *expectContinueReader. When writeLoop first reads it, it writes 100-continue to client. But (*expectContinueReader).resp.conn.bufw &#x3D;&#x3D; nil, so it leads to panic. If writeBody happens before assign，it leads to data race.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;io&quot;</span></span><br><span class="line">    <span class="string">&quot;io/ioutil&quot;</span></span><br><span class="line">    <span class="string">&quot;log&quot;</span></span><br><span class="line">    <span class="string">&quot;net/http&quot;</span></span><br><span class="line">    <span class="string">&quot;net/http/httputil&quot;</span></span><br><span class="line">    <span class="string">&quot;net/url&quot;</span></span><br><span class="line">    <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> zeroReader <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(zeroReader)</span></span> Read(p []<span class="type">byte</span>) (<span class="type">int</span>, <span class="type">error</span>) &#123; <span class="keyword">return</span> <span class="built_in">len</span>(p), <span class="literal">nil</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> infinite io.Reader = &amp;zeroReader&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">brokenBackend</span><span class="params">()</span></span> &#123;</span><br><span class="line">    http.HandleFunc(<span class="string">&quot;/&quot;</span>, <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">        conn, bfw, err := w.(http.Hijacker).Hijack()</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Fatalf(<span class="string">&quot;hijack failed: %v&quot;</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Tell client net/http.(*persistConn).writeLoop() to continue writeBody.</span></span><br><span class="line">        bfw.WriteString(<span class="string">&quot;HTTP/1.1 100 Continue\r\n\r\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Send client a wrong format header to make client net/http.(*persistConn).readLoop() readResponse failed.</span></span><br><span class="line">        <span class="comment">// Then client net/http.(*persistConn).roundTrip() will return an error and probably doesn&#x27;t wait</span></span><br><span class="line">        <span class="comment">// net/http.(*persistConn).writeLoop() to exit.</span></span><br><span class="line">        bfw.WriteString(<span class="string">&quot;BROKEN-HEADER\r\n\r\n&quot;</span>)</span><br><span class="line">        bfw.Flush()</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Keep this connection for 1s so that the client doesn&#x27;t think the connection is down immediately.</span></span><br><span class="line">        &lt;-time.AfterFunc(time.Second, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; conn.Close() &#125;).C</span><br><span class="line">    &#125;)</span><br><span class="line">    http.ListenAndServe(<span class="string">&quot;localhost:8081&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Proxy just forwards requests to the broken backend.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">proxy</span><span class="params">()</span></span> &#123;</span><br><span class="line">    target, err := url.Parse(<span class="string">&quot;http://localhost:8081&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        log.Fatalf(<span class="string">&quot;parse target url failed: %v&quot;</span>, err)</span><br><span class="line">    &#125;</span><br><span class="line">    p := httputil.NewSingleHostReverseProxy(target)</span><br><span class="line">    p.ErrorLog = log.New(ioutil.Discard, <span class="string">&quot;&quot;</span>, <span class="number">0</span>)</span><br><span class="line">    http.ListenAndServe(<span class="string">&quot;localhost:8080&quot;</span>, p)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">go</span> brokenBackend()</span><br><span class="line">    <span class="keyword">go</span> proxy()</span><br><span class="line">    <span class="comment">// Wait backend and proxy server to start</span></span><br><span class="line">    time.Sleep(time.Second)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">range</span> time.Tick(time.Millisecond * <span class="number">100</span>) &#123;</span><br><span class="line">        req, err := http.NewRequest(<span class="string">&quot;PUT&quot;</span>, <span class="string">&quot;http://localhost:8080&quot;</span>, io.LimitReader(infinite, <span class="number">65536</span>))</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Fatalf(<span class="string">&quot;create request failed: %v&quot;</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">        req.Header.Set(<span class="string">&quot;Expect&quot;</span>, <span class="string">&quot;100-continue&quot;</span>)</span><br><span class="line">        _, err = http.DefaultClient.Do(req)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Fatalf(<span class="string">&quot;do request failed: %v&quot;</span>, err)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/04/10/hello-world/</url>
    <content><![CDATA[<p>Hello World!</p>
]]></content>
  </entry>
</search>
